#!/bin/bash

# sets up directory structure and scripts to run mutect
# variant analysis and submits jobs to queue

BASEDIR="$( cd "$( dirname "$0" )" && pwd )"
GATK_DIR=$BASEDIR/../../variant_calling/gatk3
IMAGE_DIR=$BASEDIR/../../resources/images

GATK_VERSION=3.2-2
SAMTOOLS_VERSION=0.1.18
PICARD_VERSION=1.91
R_VERSION=3.1.0
NXTGENUTILS_VERSION=0.13.0
JAVA_VERSION=jdk-7u25
JAVA_VERSION_MUTECT=sun-jdk-1.6.0_19
MUTECT_VERSION=1.1.4
BEDTOOLS_VERSION=2.13.3

module load bedtools/$BEDTOOLS_VERSION

#now
NOW="date +%Y-%m-%d%t%T%t"

#today
TODAY=`date +%Y-%m-%d`
#TODAY="2014-10-29"

#get the directory this script resides in
GROUP_VOL_CGI=/project/tgu
DEPLOYMENT_SERVER=eliot.med.ic.ac.uk
DEPLOYMENT_BASE_DIR=/www/html/report
QUEUE=pqcgi

#GATK configuration
#resources
BUNDLE=$GROUP_VOL_CGI/resources/GATK_resource_bundle/2.8/b37
INDELS_1000G=$BUNDLE/1000G_phase1.indels.b37.vcf
INDELS_GOLDSTD=$BUNDLE/Mills_and_1000G_gold_standard.indels.b37.vcf
DBSNP=$BUNDLE/dbsnp_138.b37.vcf

#downsampling
WG_EXOME_SEQ_DOWNSAMPLING=250
TARGET_SEQ_DOWNSAMPLING=2000

DOWNSAMPLING=$WG_EXOME_SEQ_DOWNSAMPLING

#BAM splitting
BAM_SPLIT_MAX_THREADS=16

#RealignerTargetCreator data threads
RTC_DATATHREADS=2

#RealignRecalibrate data threads
RR_DATATHREADS=$RTC_DATATHREADS

#PrintReads CPU threads
PR_DATATHREADS=4
PR_CPUTHREADS=$PR_DATATHREADS

#path to text file containing usage information
USAGE="$BASEDIR/mutect.usage"

# default values for input arguments
REFERENCE_DIR=$GROUP_VOL_CGI/resources/reference/hsapiens/hs37d5
REFERENCE_FASTA=$REFERENCE_DIR/fasta/hs37d5.fa
REFERENCE_SEQ_DICT=$REFERENCE_DIR/dict/hs37d5.dict
#REFERENCE_CHUNKS_GENOME=$REFERENCE_DIR/hs37d5.chunks.genome.SM.bed
## need to find or make SM chunk file, because chunks without decoy required for the whole genome
REFERENCE_CHUNKS_GENOME=$REFERENCE_DIR/chunk/hs37d5.chunks.genome.bed
REFERENCE_CHUNKS_EXOME=$REFERENCE_DIR/chunk/hs37d5.chunks.exome.bed
REFERENCE_CHUNKS_TARGETED=$REFERENCE_DIR/chunk/hs37d5.chunks.targeted.bed
REFERENCE_CHUNKS_USER=""
TARGET_INTERVALS_BED=""
TYPE="WGS"
PRIMER_COORD_BED=""
PRIMER_COORD_OFFSET=10
MUTECT_COSMIC=$GROUP_VOL_CGI/resources/annotations/Cosmic_v70_hs37d5.vcf
MUTECT_DBSNP=$GROUP_VOL_CGI/resources/annotations/dbsnp_b142_GRCh37p13.vcf


#parse command line args
while getopts "n:s:r:d:u:a:t:p:o:c:m:" OPTION; do

    case "$OPTION" in
	n) PROJECT="$OPTARG";;
	s) SAMPLE_LIST="$OPTARG";;
	r) REFERENCE_FASTA="$OPTARG";;
	d) REFERENCE_SEQ_DICT="$OPTARG";;
	u) REFERENCE_CHUNKS_USER="$OPTARG";;
	a) TARGET_INTERVALS_BED="$OPTARG";;
	t) TYPE="$OPTARG";;
	p) PRIMER_COORD_BED="$OPTARG";;
	o) PRIMER_COORD_OFFSET="$OPTARG";;
	c) MUTECT_COSMIC="$OPTARG";;
	m) MUTECT_DBSNP="$OPTARG";;
	h) cat $USAGE; exit 0;;
	[?]) cat $USAGE; exit 1;;
    esac

done

#check if all required arguments are present...
if [[ -z $PROJECT ]] || \
   [[ -z $SAMPLE_LIST ]] || \
   [[ -z $REFERENCE_FASTA ]] || \
   [[ -z $REFERENCE_SEQ_DICT ]] || \
   [[ -z $TYPE ]] || \
   [[ -z $MUTECT_COSMIC ]] || \
   [[ -z $MUTECT_DBSNP ]]
then

        #...if not print usage and exit
        cat $USAGE
        exit 1
fi


#check if input files and directories exist and args a valid

#check if input directory exists
if [[ ! -d $GROUP_VOL_CGI/results/$PROJECT/mergetag ]]; then
        echo "`$NOW`ERROR: $GROUP_VOL_CGI/results/$PROJECT/mergetag is not a directory."
        exit 1
fi

#check if sample list file exists
if [[ ! -e $SAMPLE_LIST ]]; then
        echo "`$NOW`ERROR: sample list file does not exist: $SAMPLE_LIST"
        exit 1
fi

#check if reference fasta exists
if [[ ! -e $REFERENCE_FASTA ]]; then
        echo "`$NOW`ERROR: reference sequence file does not exist: $REFERENCE_FASTA"
        exit 1
fi

#check if reference dictionary exists
if [[ ! -e $REFERENCE_SEQ_DICT ]]; then
        echo "`$NOW`ERROR: reference dictionary file does not exist: $REFERENCE_SEQ_DICT"
        exit 1
fi

#check if cosmic vcf exists
if [[ ! -e $MUTECT_COSMIC ]]; then
        echo "`$NOW`ERROR: cosmic vcf file does not exist: $MUTECT_COSMIC"
        exit 1
fi

#check if dbsnp vcf exists
if [[ ! -e $MUTECT_DBSNP ]]; then
        echo "`$NOW`ERROR: dbsnp vcf file does not exist: $MUTECT_DBSNP"
        exit 1
fi

#check if target intervals bed exists
if [[ $TARGET_INTERVALS_BED != ""  ]] && [[ ! -e $TARGET_INTERVALS_BED ]]; then
	echo "`$NOW`ERROR: target interval BED file does not exist: $TARGET_INTERVALS_BED"
        exit 1
fi
    
#check if primer coord bed exists
if [[ $PRIMER_COORD_BED != ""  ]] && [[ ! -e $PRIMER_COORD_BED ]]; then
	echo "`$NOW`ERROR: primer/probe genomic coordinate BED file does not exist: $PRIMER_COORD_BED"
        exit 1
fi

#set up chunks depend on type of NGS data
if [[ "$TYPE" == "TARGETED" ]]; then

	#make sure target/amplicon intervals were supplied
	if [[ $TARGET_INTERVALS_BED == ""  ]]; then
		echo "`$NOW`ERROR: for targeted sequencing data target- or amplicon-coordinates in BED format have to be supplied via the -a command line argument."
	        exit 1
	fi

	#for high coverage targeted sequencing data
	#HaplotypeCaller will run too long if executed
	#on all targets simultaneously
	REFERENCE_CHUNKS=$REFERENCE_CHUNKS_TARGETED
			
	#set downsampling
	DOWNSAMPLING=$TARGET_SEQ_DOWNSAMPLING

elif [[ "$TYPE" == "EXOME" ]]; then

	#make sure target/amplicon intervals were supplied
#	if [[ $TARGET_INTERVALS_BED == ""  ]] 
#	then
#		echo "`$NOW`ERROR: for exome sequencing data amplicon coordinates in BED format have to be supplied via the -a command line argument, e.g. /groupvol/cgi/resources/target/exome/SureSelect_All_Exon_50M_hg19.tab.bed"
#	        exit 1
#	fi

	#use exome chunks for exome sequencing
	REFERENCE_CHUNKS=$REFERENCE_CHUNKS_EXOME

elif [[ "$TYPE" == "WGS" ]]; then

	#use exome chunks for exome sequencing
	REFERENCE_CHUNKS=$REFERENCE_CHUNKS_GENOME

else

	echo "`$NOW`ERROR: invalid value for sequencing type option (-t) option : $TYPE."
	echo "`$NOW`allowed values: WGS, EXOME, TARGETED."
        exit 1

fi


if [[ "$REFERENCE_CHUNKS_USER" != "" ]] && [[ -e $REFERENCE_CHUNKS_USER ]]; then

        REFERENCE_CHUNKS=$REFERENCE_CHUNKS_USER

elif [[ "$REFERENCE_CHUNKS_USER" != "" ]] && [[ ! -e $REFERENCE_CHUNKS_USER ]]; then

	echo "`$NOW`ERROR: user-defined chunk file does not exist: $REFERENCE_CHUNKS_USER"
        exit 1
fi


#get chunk count
TOTAL_CHUNK_COUNT=0

for CHUNK_NAME in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`; do
	
	if [[ $CHUNK_NAME != ""  ]]; then
		TOTAL_CHUNK_COUNT=$(( $TOTAL_CHUNK_COUNT + 1 ))
	fi
	
done




#FUNCTIONS
####################################################

#creates job scripts
function submitSplitBam {

	#get args
	local input_bam=$1
	local analysis_dir=$2
	local results_dir=$3

	local run_dir=$analysis_dir/run    
	local input_bam_name=`basename $input_bam .bam`
	local sample=$input_bam_name

	#create directory structure for samples
	mkdir -p $analysis_dir
	mkdir -p $results_dir
	mkdir -p $run_dir
	mkdir -p $analysis_dir/chunks

	#realignment and recalibration
	mkdir -p $analysis_dir/realignment

	mkdir -p $analysis_dir/recalibration/reports/pre
	mkdir -p $analysis_dir/recalibration/reports/post

	mkdir -p $results_dir/recalibration/reports/pre
	mkdir -p $results_dir/recalibration/reports/post
	mkdir -p $results_dir/recalibration/plots/post

	#configure script to print progress summary for submitted jobs
	#if job is completed and log file is created in /run directory
	#script examines whether the output files are in place and not empty
	local summary_script_path=$run_dir/summary_mutect.$sample.pl
	cp $BASEDIR/summary_mutect.pl $summary_script_path
	chmod 770 $summary_script_path

	sed -i -e "s/projectDirAnalysis/${ANALYSIS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/projectDirResults/${RESULTS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/#project/$PROJECT/" $summary_script_path
	sed -i -e "s/#today/$TODAY/" $summary_script_path
	sed -i -e "s/deploymentServer/$DEPLOYMENT_SERVER/" $summary_script_path
	sed -i -e "s/summaryDeployment/${SUMMARY_DEPLOYMENT//\//\\/}/" $summary_script_path
	sed -i -e "s/summaryResults/${ANALYSIS_DIR_MSVC//\//\\/}/" $summary_script_path
	sed -i -e "s/sampleList/${SAMPLE_LIST//\//\\/}/" $summary_script_path
	sed -i -e "s/refChunks/${REFERENCE_CHUNKS//\//\\/}/" $summary_script_path
	sed -i -e "s/refIntervals/null/" $summary_script_path
	sed -i -e "s/#type/$TYPE/" $summary_script_path
	sed -i -e "s/encryptedDir/$INC_DIR/" $summary_script_path

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Split BAM for $sample"
	echo "`$NOW`====================================================================================="
 
	local chunk_bed_name=`basename $REFERENCE_CHUNKS .bed`

	#get chunk count
	local chunk_ids=(`cut -f5 $REFERENCE_CHUNKS | uniq | awk '/^\s*$/ {next;} {print}'`)
	local chunk_count=`cut -f5 $REFERENCE_CHUNKS | uniq | awk '/^\s*$/ {next;} {print}' | wc -l`
	
	#calculate number of jobs required
	local job_count=`perl -e "use POSIX qw(ceil); print ceil($chunk_count/$BAM_SPLIT_MAX_THREADS);"`

	echo "`$NOW`splitting input BAM $input_bam_name into $chunk_count chunks" 
	echo "`$NOW`max. $BAM_SPLIT_MAX_THREADS chunks per job" 
	echo "`$NOW`$job_count jobs required"

	#initialise file to store job ids for
	#realignment and recalibration job dependencies
	echo -n "" > $run_dir/realign_recalibrate_dependencies.tsv

	#store bam size info to calculate required tmp space for each job 
	local bam_size=`du $input_bam | cut -f 1`
	echo -e "$input_bam_name\t$bam_size\t$chunk_count" >> $BAM_SIZE_FILE

	#for each subset of chunks...
	local subset_count=0
	for (( c=0; c<$chunk_count; c=c+$BAM_SPLIT_MAX_THREADS )); do
            
		local from=$c
		local to=$(($c+$BAM_SPLIT_MAX_THREADS-1))

		if [ $to -ge $chunk_count ]; then 
			to=$(($chunk_count-1)) 
		fi

		subset_count=$(($subset_count+1))
		local subset_bed=$run_dir/$chunk_bed_name.subset_${subset_count}.bed

		local last_subset=F

		if [[ $subset_count -eq $job_count ]]; then
			last_subset=T
		fi

		echo "`$NOW`-------------------------------------------------------------------------------------"
		echo "`$NOW`processing chunk subset $subset_count of $job_count..."

		#initialise subset BAM
		echo -n "" > $subset_bed

		#...create subset BED file
		local subset_threads=0
		for (( i=$from; i<=$to; i=i+1 )); do
	
			local chunk_id=${chunk_ids[$i]}
			cat $REFERENCE_CHUNKS | awk "{ if (\$5==$chunk_id) { print; } } " >> $subset_bed
	
			subset_threads=$(($subset_threads+1))
		
		done
	
		#calculate temp space
		local file_size_gb=`du $input_bam | perl -e '$in=<>; $in; @tokens=split(/\t/, $in); $size=$tokens[0]; $size_mb=$size/1024; $size_gb=$size_mb/1024; printf("%.0f",$size_gb);'`
		#echo $file_size_gb
		local tmpspace=$(($file_size_gb*2))

		local subset_count_formatted=`printf "%.3d\n" $subset_count`
	
		#...create and configuring job script
		script_path=$run_dir/SB_${input_bam_name}_${subset_count_formatted}.sh
		cp $GATK_DIR/splitBam.sh $script_path

		local output_dir=$analysis_dir/chunks

		sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
		sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
		sed -i -e "s/#sample/$sample/" $script_path
		sed -i -e "s/#inputBam/${input_bam//\//\\/}/" $script_path
		sed -i -e "s/#runDir/${run_dir//\//\\/}/" $script_path
		sed -i -e "s/#outputDir/${output_dir//\//\\/}/" $script_path
		sed -i -e "s/#chunkBed/${subset_bed//\//\\/}/" $script_path
		sed -i -e "s/#threads/$subset_threads/" $script_path
		sed -i -e "s/#tmpSpaceGb/$tmpspace/g" $script_path
		sed -i -e "s/#subset/subset_${subset_count}/" $script_path
		sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path
		sed -i -e "s/#lastSubset/$last_subset/" $script_path
	
   		log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

		#submit job and save job ID to dependency variable
		echo "`$NOW`submitting job script $script_path..."   		
   		local job_id=`qsub -o $log_output_path $script_path` 
		echo "`$NOW`job ID: $job_id"
		echo "`$NOW`-------------------------------------------------------------------------------------"
    		       
		#store job id for realignment and recalibration dependency
		for (( i=$from; i<=$to; i=i+1 )); do
	
			local chunk_id=${chunk_ids[$i]}
			echo -e "$chunk_id\t$job_id" >> $run_dir/realign_recalibrate_dependencies.tsv	
		
		done
		
	done
}

function submitRealignmentAndRecalibrationJobs {

	#get args
	local sample=$1
	local partner_name=$2
	local analysis_dir=$3
	local results_dir=$4
	local normal=$5

	local run_dir=$analysis_dir/run    

	######### script 1: indel realignment and base call score recalibration

	local recalibration_reports=""
	local dependency_realign_recal=afterok
	local summary_script_path=$run_dir/summary_mutect.$sample.pl

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Realign & recalibrate $sample"
	echo "`$NOW`====================================================================================="
 
	local chunk_count=0
	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`; do

		if [[ $chunk_name != ""  ]]; then 
			
			chunk_count=$(( $chunk_count + 1 ))			
			local includes_unmapped=F

			echo "`$NOW`-------------------------------------------------------------------------------------"
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."
				
			local chunk="chunk_$chunk_name"

			local chunk_int=$analysis_dir/chunks/$chunk.intervals
			local chunk_bed=$analysis_dir/chunks/$chunk.bed

			echo "`$NOW`creating chunk interval file..."
			#converting BED to interval list skipping blank lines
			#converting to chr:start-end format instead of tab delimited format
			#as GATK started to refuse parsing tab delimited format for some reason
			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $chunk_int
 		
			echo "`$NOW`creating chunk BED file..."
			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS > $chunk_bed

			if [[ $chunk_count -eq $TOTAL_CHUNK_COUNT ]]; then
				includes_unmapped=T
			fi

			#we want to creat indel realignment targets for tumor and normal 
			#samples at the sames time to reduce the rate of false positives
			local chunk_bam=$analysis_dir/chunks/$sample.$chunk.bam
			local partner_analysis_dir=`dirname $analysis_dir`
			local chunk_partner_bam=$partner_analysis_dir/$partner_name/chunks/$partner_name.$chunk.bam

			echo "`$NOW`creating and submitting job script to realign and recalibrate chunk..."

			local total_file_size_mb=0
			for file in $INDELS_1000G $INDELS_GOLDSTD $DBSNP $REFERENCE_FASTA ; do

			    local file_size_kb=`du $file | cut -f1`
			    if [ $file_size_kb != 0 ]; then
				local file_size_mb=$(( $file_size_kb / 1024 ))
			    fi
			    total_file_size_mb=$(( $total_file_size_mb + $file_size_mb ))

			done

			local bam_size=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f2`
			local chunks_total=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f3`
			local bam_chunk_size=$(( $bam_size / $chunks_total ))
			local bam_chunk_size_mb=$(( $bam_chunk_size / 1024 ))
			total_file_size_mb=$(( $total_file_size_mb + $bam_chunk_size_mb ))

			local tmp_space_mb=$(( $total_file_size_mb * 2 )) 

			local chunk_formatted=`printf "%.3d\n" $chunk_name`
 			local script_path=$run_dir/RR_${sample}_${chunk_formatted}.sh
			cp $GATK_DIR/gatk3_realign_recalibrate.sh $script_path

			sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
			sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
			sed -i -e "s/#picardVersion/$PICARD_VERSION/" $script_path
			sed -i -e "s/#rVersion/$R_VERSION/" $script_path	
			sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
    	  	        sed -i -e "s/#nxtGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path
    	  		sed -i -e "s/#tmpSpaceMb/$tmp_space_mb/g" $script_path

			sed -i -e "s/#indels1000G/${INDELS_1000G//\//\\/}/" $script_path	
			sed -i -e "s/#indelsGoldStd/${INDELS_GOLDSTD//\//\\/}/" $script_path
			sed -i -e "s/#dbSnp/${DBSNP//\//\\/}/" $script_path

			#merge tumor and normal bam chunks to find indel realignment targets
			local string_gatk="# create target intervals for IndelRealigner"
			local string_mutect="cp $chunk_partner_bam \$TMPDIR/chunk.partner.bam\n \
samtools view -H \$TMPDIR/chunk.bam > \$TMPDIR/header.dict.sam\n \
samtools view -H \$TMPDIR/chunk.partner.bam|grep -P '^@RG' > \$TMPDIR/header.partner.sam\n \
cat \$TMPDIR/header.dict.sam \$TMPDIR/header.partner.sam > \$TMPDIR/header.sam\n \
samtools merge -h \$TMPDIR/header.sam \$TMPDIR/chunk.combined.bam \$TMPDIR/chunk.bam \$TMPDIR/chunk.partner.bam\n \
samtools index \$TMPDIR/chunk.combined.bam\n \
ls -l\n \
# create target intervals for IndelRealigner"
			sed -i -e "s/${string_gatk//\//\\/}/${string_mutect//\//\\/}/" $script_path

			local string_gatk="RealignerTargetCreator -I \$TMPDIR\/chunk.bam"
			local string_mutect="RealignerTargetCreator -I \$TMPDIR/chunk.combined.bam"
			sed -i -e "s/$string_gatk/${string_mutect//\//\\/}/" $script_path

			#don't remove bam chunks untill all realignment jobs are completed
			local string_gatk="rm \$INPUT_BAM \$INPUT_BAM.bai"
			local string_mutect="#rm \$INPUT_BAM \$INPUT_BAM.bai"
			sed -i -e "s/$string_gatk/${string_mutect//\//\\/}/" $script_path

			sed -i -e "s/#inputBam/${chunk_bam//\//\\/}/" $script_path
			sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
			sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
			sed -i -e "s/#referenceSeqDict/${REFERENCE_SEQ_DICT//\//\\/}/" $script_path
			sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
			sed -i -e "s/#fragmentName/$chunk/" $script_path
			sed -i -e "s/#dataThreads/$RR_DATATHREADS/" $script_path   
			sed -i -e "s/#rtcDataThreads/$RTC_DATATHREADS/" $script_path
			sed -i -e "s/#sample/$sample/" $script_path
			sed -i -e "s/#includesUnmapped/$includes_unmapped/" $script_path
			sed -i -e "s/#primerCoordBed/${PRIMER_COORD_BED//\//\\/}/" $script_path
			sed -i -e "s/#primerCoordOffset/$PRIMER_COORD_OFFSET/" $script_path
			sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path


			## change from GATKv2 pipeline - we output all reads, not just target region
#			if [[ $TARGET_INTERVALS_BED != ""  ]]; then

#				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
#				sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path
#			else
				sed -i -e "s/#fragmentFile/${chunk_int//\//\\/}/" $script_path
#			fi

			## for targeted sequencing base recalibration should be done on targets only
			## This excludes off-target sequences and sequences that may be poorly mapped, which have a higher error rate. Including them could lead to a skewed model and bad recalibration.
			## also RealignerTargetCreator only for target regions, for speed
			## see http://gatkforums.broadinstitute.org/discussion/4133/when-should-i-use-l-to-pass-in-a-list-of-intervals#latest

			if [[ $TARGET_INTERVALS_BED != ""  ]]; then
				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
				sed -i -e "s/#targetFile/${target_int//\//\\/}/" $script_path
			else
				sed -i -e "s/#targetFile/${chunk_int//\//\\/}/" $script_path
			fi

			recalibration_reports="$recalibration_reports $analysis_dir/recalibration/reports/pre/$sample.$chunk.realigned.recal_data.grp"

			#submit job and save job ID to dependency variable
			local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    		
			#get BAM split dependency, run this job only after tumor and normal splits are completed
			local split_dependency=`cat $run_dir/realign_recalibrate_dependencies.tsv | grep -P "^$chunk_name\t" | cut -f2` 
			local split_partner_dependency=`cat $partner_analysis_dir/$partner_name/run/realign_recalibrate_dependencies.tsv | grep -P "^$chunk_name\t" | cut -f2` 
    		
			echo "`$NOW`$script_path"
			local job_id=`qsub -o $log_output_path -W depend=afterok:$split_dependency:$split_partner_dependency $script_path`
			dependency_realign_recal="$dependency_realign_recal:$job_id"
			echo "`$NOW`job ID: $job_id"    		        
			echo "`$NOW`-------------------------------------------------------------------------------------"
		
		fi

	done


	########## script 2: merge chunk recalibration reports

	local dependency_merge_recal=afterok
	local merged_recal_report=$results_dir/recalibration/reports/pre/$sample.realigned.recal_data.grp

	#create and configure script to merge chunk recalibration reports

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Merge recalibration reports $sample"
	echo "`$NOW`====================================================================================="

	script_path=$run_dir/MR_${sample}_000.sh
	cp $GATK_DIR/gatk3_merge_recalibration_reports.sh $script_path

	sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
	sed -i -e "s/#recalibrationReports/${recalibration_reports//\//\\/}/" $script_path
	sed -i -e "s/#mergedRecalibrationReport/${merged_recal_report//\//\\/}/" $script_path
	sed -i -e "s/#nxtGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path

	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
	sed -i -e "s/#sample/$sample/" $script_path
	sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path

	#submit job and save job ID to dependency variable
	log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

	echo "`$NOW`$script_path"
	job_id=`qsub -o $log_output_path -W depend=$dependency_realign_recal $script_path`
	echo "`$NOW`job ID: $job_id"
	dependency_merge_recal=$dependency_merge_recal:$job_id

	#add sample to PrintReads dependency file
	echo -n -e "$sample\t" >> $PRINT_READS_DEPENDENCY

	#reset chunk count
	chunk_count=0

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Print reads $sample"
	echo "`$NOW`====================================================================================="

	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`; do

		if [[ $chunk_name != ""  ]]; then 

			chunk_count=$(( $chunk_count + 1 ))	
			echo "`$NOW`-------------------------------------------------------------------------------------"	 
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."

			chunk="chunk_$chunk_name"
			local chunk_int=$analysis_dir/chunks/$chunk.intervals
		
			########## script 3: print reads with recalibrated quality scores 

			#create and configure script to print reads with recalibrated quality scores 

			local realigned_bam_file=$analysis_dir/realignment/$sample.$chunk.realigned.bam
			local realigned_recalibrated_bam_file=$analysis_dir/recalibration/$sample.$chunk.realigned.recalibrated.bam

			local includes_unmapped=F
			if [[ $chunk_count -eq $TOTAL_CHUNK_COUNT ]]; then
				includes_unmapped=T
			fi

			local total_file_size_mb=0
			for file in $REFERENCE_FASTA ; do

			    local file_size_kb=`du $file | cut -f1`
			    if [ $file_size_kb != 0 ]; then
				local file_size_mb=$(( $file_size_kb / 1024 ))
			    fi
			    total_file_size_mb=$(( $total_file_size_mb + $file_size_mb ))

			done

			local bam_size=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f2`
			local chunks_total=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f3`
			local bam_chunk_size=$(( $bam_size / $chunks_total ))
			local bam_chunk_size_mb=$(( $bam_chunk_size    / 1024 ))
			total_file_size_mb=$(( $total_file_size_mb + $bam_chunk_size_mb ))

			local tmp_space_mb=$(( $total_file_size_mb * 2 ))
		
			echo "`$NOW`creating and submitting job script to print recalibrated reads..."
 			local chunk_formatted=`printf "%.3d\n" $chunk_name`
 			script_path=$run_dir/PR_${sample}_${chunk_formatted}.sh
			cp $GATK_DIR/gatk3_print_reads.sh $script_path

			sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
			sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
			sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
			sed -i -e "s/#nextGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path
    	  		sed -i -e "s/#tmpSpaceMb/$tmp_space_mb/g" $script_path

			sed -i -e "s/#cpuThreads/$PR_CPUTHREADS/" $script_path
			sed -i -e "s/#nctThreads/$PR_DATATHREADS/" $script_path
			sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
			sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
			sed -i -e "s/#referenceSeqDict/${REFERENCE_SEQ_DICT//\//\\/}/" $script_path
			sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
			sed -i -e "s/#sample/$sample/" $script_path
			sed -i -e "s/#fragmentName/$chunk/" $script_path
			sed -i -e "s/#realignedBamFile/${realigned_bam_file//\//\\/}/" $script_path
			sed -i -e "s/#recalibrationReport/${merged_recal_report//\//\\/}/" $script_path
			sed -i -e "s/#recalibratedBamOutput/${realigned_recalibrated_bam_file//\//\\/}/" $script_path
			sed -i -e "s/#includesUnmapped/$includes_unmapped/" $script_path
			sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path

			## change from GATKv2 pipeline - we output all reads, not just target region
#			if [[ $TARGET_INTERVALS_BED != ""  ]]; then

#				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
#				sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path
#			else
				sed -i -e "s/#fragmentFile/${chunk_int//\//\\/}/" $script_path
#			fi

			## for targeted sequencing base recalibration should be done on targets only
			## This excludes off-target sequences and sequences that may be poorly mapped, which have a higher error rate. Including them could lead to a skewed model and bad recalibration.
			## also RealignerTargetCreator only for target regions, for speed
			## see http://gatkforums.broadinstitute.org/discussion/4133/when-should-i-use-l-to-pass-in-a-list-of-intervals#latest

			if [[ $TARGET_INTERVALS_BED != ""  ]]; then
				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
				sed -i -e "s/#targetFile/${target_int//\//\\/}/" $script_path
			else
				sed -i -e "s/#targetFile/${chunk_int//\//\\/}/" $script_path
			fi

		
			#submit job and save job ID to dependency variable
			log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

			echo "`$NOW`$script_path"
			job_id=`qsub -o $log_output_path -W depend=$dependency_merge_recal $script_path`
	                echo "`$NOW`job ID: $job_id"
 
			#store job ID in PrintReads dependencies file
			if [[ $chunk_count -ne $TOTAL_CHUNK_COUNT ]]; then
				echo -n -e "$job_id\t" >> $PRINT_READS_DEPENDENCY
			else
				echo "$job_id" >> $PRINT_READS_DEPENDENCY
			fi
			
			echo "`$NOW`-------------------------------------------------------------------------------------"
	
		fi

	done

	#change permissions on all directories/files created
	chmod -R 770 $analysis_dir
	chmod -R 770 $results_dir

}


function submitMuTect {

	local sample_normal=$1
	local sample_tumor=$2
	local analysis_dir=$3
	local results_dir=$4
	local sample_name=`basename $results_dir`

	#create output directories
	mkdir -p $analysis_dir/chunks
       	mkdir -p $analysis_dir/run
       	mkdir -p $analysis_dir/mutect
       	mkdir -p $results_dir

	#configure perl script to print progress summary for submitted jobs
	#if job is completed and log file is created in /run directory
	#script examines whether the output files are in place and not empty
	local summary_script_path=$analysis_dir/run/summary_mutect.$sample_name.pl
	cp $BASEDIR/summary_mutect.pl $summary_script_path
	chmod 770 $summary_script_path

	sed -i -e "s/projectDirAnalysis/${ANALYSIS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/projectDirResults/${RESULTS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/#project/$PROJECT/" $summary_script_path
	sed -i -e "s/#today/$TODAY/" $summary_script_path
	sed -i -e "s/deploymentServer/$DEPLOYMENT_SERVER/" $summary_script_path
	sed -i -e "s/summaryDeployment/${SUMMARY_DEPLOYMENT//\//\\/}/" $summary_script_path
	sed -i -e "s/summaryResults/${ANALYSIS_DIR_MSVC//\//\\/}/" $summary_script_path
	sed -i -e "s/sampleList/${SAMPLE_LIST//\//\\/}/" $summary_script_path
	sed -i -e "s/refChunks/${REFERENCE_CHUNKS//\//\\/}/" $summary_script_path
	sed -i -e "s/#type/$TYPE/" $summary_script_path

	######### script 4: merge, recalibrating and filtering raw VCF files run MuTect for each chunk

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Run MuTect for $sample_normal and $sample_tumor"
	echo "`$NOW`====================================================================================="

	local dependency_mutect=afterok

	local chunk_count=0
	local raw_stats_files=""
	local raw_vcf_files=""
	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
	do	
	
		if [[ $chunk_name != ""  ]]
		then 

			chunk_count=$(( $chunk_count + 1 ))	
			echo "`$NOW`-------------------------------------------------------------------------------------"	 
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."

			chunk="chunk_$chunk_name"
			analysis_file=$analysis_dir/mutect/$sample_name.$chunk

			#converting BED to interval list skipping blank lines
			#converting to chr:start-end format instead of tab delimited format 
			local chunk_int=$analysis_dir/chunks/$sample_name.$chunk.intervals
			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $chunk_int
		
		        local normal_bam="$ANALYSIS_DIR_PROJECT/$TODAY/$sample_normal/recalibration/$sample_normal.$chunk.realigned.recalibrated.bam"
			local tumor_bam="$ANALYSIS_DIR_PROJECT/$TODAY/$sample_tumor/recalibration/$sample_tumor.$chunk.realigned.recalibrated.bam"

			#get PrintReads job IDs for multi-sample calling job dependencies
			local dependency_print_reads=afterok
			local job_id_column=$(( $chunk_count + 1 ))
			for job_id_record in `grep -P "^$sample_normal\t|^$sample_tumor\t" $PRINT_READS_DEPENDENCY|cut -f$job_id_column` 
			do

				#check if job is still in the queue (either running or queuing)
				#select jobs that are
				#'Q'ueued
				#'R'unning
				#'H'eld
				#'S'uspended
				#'W'aiting
				local alive=`qselect -s QRHSW | grep $job_id_record`
				if [[ $alive != "" ]]
				then
					echo "`$NOW`adding job $job_id_record to mutect dependencies..."
					dependency_print_reads="$dependency_print_reads:$job_id_record"
				fi			

			done;

			########## script 4: run MuTect

			local total_file_size_mb=0
			for file in $MUTECT_COSMIC $MUTECT_DBSNP $REFERENCE_FASTA; do

			    local file_size_kb=`du $file | cut -f1`
			    if [ $file_size_kb != 0 ]; then
				local file_size_mb=$(( $file_size_kb / 1024 ))
			    fi
			    total_file_size_mb=$(( $total_file_size_mb + $file_size_mb ))

			done

			for file in $sample_normal $sample_tumor; do

			    local bam_size=`grep -P "^$file" $BAM_SIZE_FILE|cut -f2`
			    local chunks_total=`grep -P "^$file" $BAM_SIZE_FILE|cut -f3`
			    local bam_chunk_size=$(( $bam_size / $chunks_total ))
			    local bam_chunk_size_mb=$(( $bam_chunk_size / 1024 ))
			    total_file_size_mb=$(( $total_file_size_mb + $bam_chunk_size_mb ))

			done

			local tmp_space_mb=$(( $total_file_size_mb * 2 ))

			local chunk_formatted=`printf "%.3d\n" $chunk_name`
 			local script_path=$analysis_dir/run/MU_${sample_name}_${chunk_formatted}.sh
			cp $BASEDIR/mutect.sh $script_path
		  		
			sed -i -e "s/#mutectVersion/$MUTECT_VERSION/" $script_path
			sed -i -e "s/#javaVersion/${JAVA_VERSION_MUTECT//\//\\/}/" $script_path
    	  		sed -i -e "s/#tmpSpaceMb/$tmp_space_mb/g" $script_path
			sed -i -e "s/#analysisFile/${analysis_file//\//\\/}/" $script_path
			sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
			sed -i -e "s/#referenceDict/${REFERENCE_SEQ_DICT//\//\\/}/" $script_path
			sed -i -e "s/#referenceSeqDict/${REFERENCE_SEQ_DICT//\//\\/}/" $script_path
			sed -i -e "s/#mutectCosmic/${MUTECT_COSMIC//\//\\/}/" $script_path
			sed -i -e "s/#mutectDBsnp/${MUTECT_DBSNP//\//\\/}/" $script_path
			sed -i -e "s/#normalBam/${normal_bam//\//\\/}/" $script_path
			sed -i -e "s/#tumorBam/${tumor_bam//\//\\/}/" $script_path
			sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path
			sed -i -e "s/#baseDir/${BASEDIR//\//\\/}/" $script_path

			if [[ $TARGET_INTERVALS_BED != "" ]]
			then
				
			        target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
				sed -i -e "s/#intervalsFile/${target_int//\//\\/}/" $script_path
			        
			else
				
				sed -i -e "s/#intervalsFile/${chunk_int//\//\\/}/" $script_path
			        
			fi

			#submit job and save job ID to dependency variable
			local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

			echo "`$NOW`$script_path"
			local job_id=`qsub -o $log_output_path -W depend=$dependency_print_reads $script_path`
			echo "`$NOW`job ID: $job_id"
			dependency_mutect=$dependency_mutect:$job_id

			raw_stats_files="$raw_stats_files $analysis_file.stats"
			raw_vcf_files="$raw_vcf_files $analysis_file.vcf"

			echo "`$NOW`-------------------------------------------------------------------------------------"

		fi

	done;


	######### script 5: merge and filtering raw MuTect stats files 

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Merge & filter MuTect outputs for $sample_normal and $sample_tumor"
	echo "`$NOW`====================================================================================="

	#create a script for merging stats mutect files and filter calls that don't pass quality filter
	echo "`$NOW`creating and submitting script for merging stats mutect files..."
	local script_path=$analysis_dir/run/MS_${sample_name}_000.sh
	cp $BASEDIR/merge_stats.sh $script_path
	chmod 770 $script_path

	sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
	sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
	sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
	sed -i -e "s/#referenceSeqDict/${REFERENCE_SEQ_DICT//\//\\/}/" $script_path
 	sed -i -e "s/#results_dir/${results_dir//\//\\/}/" $script_path
	sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path

	#we have to use the roundabout Perl way here as there seems to be 
        #a limit to the string length for either sed or the bash substitution 	
	#and the raw VCF string can be very long if the number of amplicons
	#is high!!!
	raw_stats_files=`echo $raw_stats_files | perl -pe "s/\//forwardSlash/g"`
	perl -i -pe "s/#rawStatsFiles/$raw_stats_files/" $script_path
	raw_vcf_files=`echo $raw_vcf_files | perl -pe "s/\//forwardSlash/g"`
	perl -i -pe "s/#rawVcfFiles/$raw_vcf_files/" $script_path
	perl -i -pe "s/forwardSlash/\//g" $script_path

	log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

	echo "`$NOW`$script_path"
	job_id=`qsub -o $log_output_path -W depend=$dependency_mutect $script_path`
	DEPENDENCY_MERGE_MUTECT="$DEPENDENCY_MERGE_MUTECT:$job_id"
	echo "`$NOW`job ID: $job_id"   

	script_path=$results_dir/$sample_name.stats.keep.php
	cp $GATK_DIR/../../helper/tsvToHtmlTable.php $script_path
 	sed -i -e "s/#tsvFile/$sample_name.stats.keep/" $script_path	
 	sed -i -e "s/#header/Mutect Summary/" $script_path

	#change permissions on all directories/files created
	chmod -R 770 $analysis_dir
	chmod -R 770 $results_dir
}

function submitPostProcessingJobs {

	#get args
	local sample=$1
	local analysis_dir=$2
	local results_dir=$3
	local run_dir=$analysis_dir/run    

	#recalibration
	mkdir -p $results_dir/recalibration

	########## script 6: merge realigned and recalibrated chunk BAM files	
	echo "`$NOW`====================================================================================="
	echo "`$NOW`Merging recalibrated chunk BAM files for $sample"
	echo "`$NOW`====================================================================================="

	local recalibrated_merged_bam_output_dir=$results_dir/recalibration
	local recalibrated_input_dir=$analysis_dir/recalibration
	local recalibrated_bam_files=""
	local chunk_count=0
	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`; do

		if [[ $chunk_name != ""  ]]; then 
			
			chunk_count=$(( $chunk_count + 1 ))
			local chunk="chunk_$chunk_count"
			recalibrated_bam_files="$recalibrated_bam_files $sample.$chunk.realigned.recalibrated.bam"

		fi
	done			

	local dependency_post_recal="afterok"

	local bam_size=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f2`
	local bam_size_mb=$(( $bam_size / 1024))
	local bam_size_gb=$(( $bam_size_mb / 1024))
	local tmp_space_gb=$(( $bam_size_gb * 10/4 ))

	echo "`$NOW`creating and submitting job script to merge recalibrated chunk BAMs..."
		
	#create and configure job script to merge realigned BAM files		
	script_path=$run_dir/MB_${sample}_000.sh
	cp $BASEDIR/merge_bam.sh $script_path

 	sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
	sed -i -e "s/#tmpSpaceGb/$tmp_space_gb/" $script_path

	sed -i -e "s/#sample/$sample/" $script_path
	sed -i -e "s/#inputDirRecalibrated/${recalibrated_input_dir//\//\\/}/" $script_path	
	sed -i -e "s/#recalibratedBam/$recalibrated_bam_files/" $script_path	
	sed -i -e "s/#pathOutputDirRecalibrated/${recalibrated_merged_bam_output_dir//\//\\/}/" $script_path

	#submit job and save job ID to dependency variable
	log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
	echo "`$NOW`$script_path"

	local dependency_mutect=`cut -f1 $MUTECT_DEPENDENCY`
	job_id=`qsub -o $log_output_path -W depend=$dependency_mutect $script_path`	
	dependency_post_recal="$dependency_post_recal:$job_id"
	echo "`$NOW`job ID: $job_id"
	
	echo "`$NOW`====================================================================================="
	echo "`$NOW`Recalibration and coverage reports for $sample"
	echo "`$NOW`====================================================================================="
	
	#script 7: post-recalibration reports on chunks
	local post_recalibration_reports=""
	
	chunk_count=0
	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`; do

		if [[ $chunk_name != ""  ]]; then 

			chunk_count=$(( $chunk_count + 1 ))
				
			echo "`$NOW`-------------------------------------------------------------------------------------"
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."
				
			local chunk="chunk_$chunk_name"

			local chunk_int=$analysis_dir/chunks/$chunk.intervals
			local chunk_bed=$analysis_dir/chunks/$chunk.bed
			local chunk_bam=$analysis_dir/realignment/$sample.$chunk.realigned.bam

			local chunk_pre_recalibration_report=$analysis_dir/recalibration/reports/pre/$sample.$chunk.realigned.recal_data.grp

			echo "`$NOW`creating and submitting job script to get post-recalibration report on chunk..."

			local total_file_size_mb=0
			for file in $INDELS_1000G $INDELS_GOLDSTD $DBSNP $REFERENCE_FASTA; do

			    local file_size_kb=`du $file | cut -f1`
			    if [ $file_size_kb != 0 ]; then
				local file_size_mb=$(( $file_size_kb / 1024 ))
			    fi
			    total_file_size_mb=$(( $total_file_size_mb + $file_size_mb ))

			done

			local bam_size=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f2`
			local chunks_total=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f3`
			local bam_chunk_size=$(( $bam_size / $chunks_total ))
			local bam_chunk_size_mb=$(( $bam_chunk_size / 1024 ))
			total_file_size_mb=$(( $total_file_size_mb + $bam_chunk_size_mb ))

			local tmp_space_mb=$(( $total_file_size_mb * 2 ))

			local chunk_formatted=`printf "%.3d\n" $chunk_name`			
 			local script_path=$run_dir/PM_${sample}_${chunk_formatted}.sh
			cp $GATK_DIR/gatk3_postrecalibration_metrics.sh $script_path

			sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
			sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
			sed -i -e "s/#picardVersion/$PICARD_VERSION/" $script_path
			sed -i -e "s/#rVersion/$R_VERSION/" $script_path
			sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
    	  		sed -i -e "s/#tmpSpaceMb/$tmp_space_mb/" $script_path

			sed -i -e "s/#indels1000G/${INDELS_1000G//\//\\/}/" $script_path	
			sed -i -e "s/#indelsGoldStd/${INDELS_GOLDSTD//\//\\/}/" $script_path
			sed -i -e "s/#dbSnp/${DBSNP//\//\\/}/" $script_path

			sed -i -e "s/#inputBam/${chunk_bam//\//\\/}/" $script_path
			sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
			sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
			sed -i -e "s/#referenceSeqDict/${REFERENCE_SEQ_DICT//\//\\/}/" $script_path
			sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
			sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path	
			sed -i -e "s/#fragmentName/$chunk/" $script_path
			sed -i -e "s/#sample/$sample/" $script_path
			sed -i -e "s/#preRecalibrationReport/${chunk_pre_recalibration_report//\//\\/}/" $script_path

			#remove bam original chunk and realigned chunk
			local chunk_bam_original=`echo $chunk_bam|sed -e 's/realignment/chunks/'|sed -e 's/realigned\.//'`
			local string_gatk="#logging"
			local string_mutect="rm $chunk_bam $chunk_bam.bai $chunk_bam_original $chunk_bam_original.bai\n\n #logging"
			sed -i -e "s/$string_gatk/${string_mutect//\//\\/}/" $script_path

			## change from GATKv2 pipeline - we output all reads, not just target region
#			if [[ $TARGET_INTERVALS_BED != ""  ]]; then

#				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
#				sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path
#			else
				sed -i -e "s/#fragmentFile/${chunk_int//\//\\/}/" $script_path
#			fi

			## for targeted sequencing base recalibration should be done on targets only
			## This excludes off-target sequences and sequences that may be poorly mapped, which have a higher error rate. Including them could lead to a skewed model and bad recalibration.
			## also RealignerTargetCreator only for target regions, for speed
			## see http://gatkforums.broadinstitute.org/discussion/4133/when-should-i-use-l-to-pass-in-a-list-of-intervals#latest

			if [[ $TARGET_INTERVALS_BED != ""  ]]; then
				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
				sed -i -e "s/#targetFile/${target_int//\//\\/}/" $script_path
			else
				sed -i -e "s/#targetFile/${chunk_int//\//\\/}/" $script_path
			fi

			post_recalibration_reports="$post_recalibration_reports $analysis_dir/recalibration/reports/post/$sample.$chunk.realigned.recalibrated.recal_data.grp"

			#submit job and save job ID to dependency variable
   			local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    		
			echo "`$NOW`$script_path"
			local job_id=`qsub -o $log_output_path -W depend=$dependency_mutect $script_path`
			dependency_post_recal="$dependency_post_recal:$job_id"	
			echo "`$NOW`job ID: $job_id"
	    		
			echo "`$NOW`-------------------------------------------------------------------------------------"
		
		fi

	done
	
	#script 8: report generation
	local merged_pre_recal_report=$results_dir/recalibration/reports/pre/$sample.realigned.recal_data.grp
	local merged_post_recal_report=$results_dir/recalibration/reports/post/$sample.realigned.recalibrated.recal_data.grp
	local post_recalibration_plots_output_dir=$results_dir/recalibration/plots/post/	
		
	echo "`$NOW`creating and submitting job script to generate summary metrics..."

	local total_file_size_mb=0
	for file in $REFERENCE_FASTA; do

	    local file_size_kb=`du $file | cut -f1`
	    if [ $file_size_kb != 0 ]; then
		local file_size_mb=$(( $file_size_kb / 1024 ))
	    fi
	    total_file_size_mb=$(( $total_file_size_mb + $file_size_mb ))

	done

	local bam_size=`grep -P "^$sample" $BAM_SIZE_FILE|cut -f2`
	local bam_size_mb=$(( $bam_size / 1024 ))
	total_file_size_mb=$(( $total_file_size_mb + $bam_size_mb ))

	local tmp_space_mb=$(( $total_file_size_mb * 2 ))
			
	local script_path=$run_dir/CS_${sample}_000.sh
	local summary_script_path=$run_dir/summary_mutect.$sample.pl
	cp $GATK_DIR/gatk3_collect_summary_metrics.sh $script_path

	sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
	sed -i -e "s/#rVersion/$R_VERSION/" $script_path
	sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
 	sed -i -e "s/#nxtGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path
    	sed -i -e "s/#tmpSpaceMb/$tmp_space_mb/" $script_path
    	  	
   	sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
	sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path
	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path

 	sed -i -e "s/#reaglignedRecalibratedBam/${recalibrated_merged_bam//\//\\/}/" $script_path
 	sed -i -e "s/#sample/$sample/" $script_path
 	sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
	sed -i -e "s/#referenceSeqDict/${REFERENCE_SEQ_DICT//\//\\/}/" $script_path

	sed -i -e "s/#mergedPreRecalibrationReport/${merged_pre_recal_report//\//\\/}/" $script_path
 	sed -i -e "s/#recalibrationReports/${post_recalibration_reports//\//\\/}/" $script_path
 	sed -i -e "s/#mergedPostRecalibrationReport/${merged_post_recal_report//\//\\/}/" $script_path
 	sed -i -e "s/#postRecalibrationPlotsOutputDir/${post_recalibration_plots_output_dir//\//\\/}/" $script_path
 	sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path
	sed -i -e "s/#sequencingType/$TYPE/" $script_path 	
 	

	if [[ $TARGET_INTERVALS_BED != ""  ]]
	then
		sed -i -e "s/#targetIntervals/${TARGET_INTERVALS_INT//\//\\/}/" $script_path
	else
		sed -i -e "s/#targetIntervals/NULL/" $script_path
	fi

 	sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path


 	#submit job and save job ID to dependency variable
   	local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    
	echo "`$NOW`$script_path"
	local job_id=`qsub -o $log_output_path -W depend=$dependency_post_recal $script_path`
	echo "`$NOW`job ID: $job_id"

	DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL="$DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL:$job_id"

	echo "`$NOW`-------------------------------------------------------------------------------------"
	chmod -R 770 $analysis_dir
	chmod -R 770 $results_dir
	
}

function submitMergeAndPlotMetricsJob {

	#get args
	local results_dir=$1
	local analysis_dir=$2
	local run_dir=$analysis_dir/run
	mkdir -p $run_dir
	chmod 770 $run_dir
	local project_name=$3
	local sample_summary="$project_name.$TODAY.sample_summary"	
	local sample_interval_summary="$project_name.$TODAY.sample_interval_summary"
	local sample_cumulative_coverage_proportions="$project_name.$TODAY.sample_cumulative_coverage_proportions"
	local dependency_collect_summary_metrics_all=`cat $ALL_JOBS_DEPENDENCY`

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Merging metrics for all samples"
	echo "`$NOW`====================================================================================="
	echo "`$NOW`creating and submitting job script to merge and plot metrics..."
		
	#create and configure job script to merge realigned BAM files		
	script_path=$run_dir/plot_summary_metrics.R
	cp $GATK_DIR/plot_summary_metrics.R $script_path
	
 	sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path	
 	sed -i -e "s/#sampleIntervalSummary/$sample_interval_summary/" $script_path	
 	sed -i -e "s/#sampleCumulativeCoverageProportions/$sample_cumulative_coverage_proportions/" $script_path	

	script_path=$run_dir/MM_00000000_000.sh
	cp $GATK_DIR/gatk3_merge_summary_metrics.sh $script_path
	transpose_table_script=$GATK_DIR/../../helper/transposeTable.R

	sed -i -e "s/#rVersion/$R_VERSION/" $script_path
 	sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path	
 	sed -i -e "s/#runDir/${run_dir//\//\\/}/" $script_path
 	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
 	sed -i -e "s/#type/$TYPE/" $script_path
	sed -i -e "s/#transposeTableScript/${transpose_table_script//\//\\/}/" $script_path
	
	local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    
	echo "`$NOW`$script_path"
	local job_id=`qsub -o $log_output_path -W depend=$dependency_collect_summary_metrics_all $script_path`

	#configure PHP scripts for coverage summary tables
	
	#sample summary
	script_path=$run_dir/sample_summary.php
	cp $GATK_DIR/../../helper/tsvToHtmlTable.php $script_path

 	sed -i -e "s/#tsvFile/$sample_summary/" $script_path	
 	sed -i -e "s/#header/Sample Coverage Summary/" $script_path

	#sample interval summary
	script_path=$run_dir/sample_interval_summary.php
	cp $GATK_DIR/../../helper/tsvToHtmlTable.php $script_path

 	sed -i -e "s/#tsvFile/$sample_interval_summary/" $script_path	
 	sed -i -e "s/#header/Sample Interval Coverage Summary/" $script_path

	#sample cumulative coverage proportions
	script_path=$run_dir/sample_cumulative_coverage_proportions.php
	cp $GATK_DIR/../../helper/tsvToHtmlTable.php $script_path

 	sed -i -e "s/#tsvFile/$sample_cumulative_coverage_proportions/" $script_path	
 	sed -i -e "s/#header/Sample Cumulative Coverage Proportions/" $script_path

	#copy tsvToXsl.pl script to run folder
	cp $GATK_DIR/../../helper/tsvToXls.pl $run_dir/

	echo "`$NOW`job ID: $job_id"
	echo "`$NOW`-------------------------------------------------------------------------------------"

	echo "`$NOW`creating and configuring summary script..."
	local summary_script_path=$run_dir/summary_mutect.${PROJECT}.pl
	cp $BASEDIR/summary_mutect.pl $summary_script_path
	chmod 770 $summary_script_path

	sed -i -e "s/projectDirAnalysis/${ANALYSIS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/projectDirResults/${RESULTS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/#project/$PROJECT/" $summary_script_path
	sed -i -e "s/#today/$TODAY/" $summary_script_path
	sed -i -e "s/deploymentServer/$DEPLOYMENT_SERVER/" $summary_script_path
	sed -i -e "s/summaryDeployment/${SUMMARY_DEPLOYMENT//\//\\/}/" $summary_script_path
	sed -i -e "s/summaryResults/${ANALYSIS_DIR_MSVC//\//\\/}/" $summary_script_path
	sed -i -e "s/sampleList/${SAMPLE_LIST//\//\\/}/" $summary_script_path
	sed -i -e "s/refChunks/${REFERENCE_CHUNKS//\//\\/}/" $summary_script_path
	sed -i -e "s/refIntervals/null/" $summary_script_path
	sed -i -e "s/#type/$TYPE/" $summary_script_path
	sed -i -e "s/encryptedDir/$INC_DIR/" $summary_script_path

	local summary_log_path=`echo $summary_script_path | perl -pe 's/\.pl/\.log/g'`
	echo "`$NOW`$summary_script_path"
	local sum_job_id=`qsub -q $QUEUE -o $summary_log_path -j oe -W depend=afterany:$job_id -M cgi@imperial.ac.uk $summary_script_path` 
	echo "`$NOW`job ID: $sum_job_id"
	echo "`$NOW`-------------------------------------------------------------------------------------"

}


function submitCompUse {

	echo "`$NOW`creating and submitting usage script..."
	local script_path=$ANALYSIS_DIR_MSVC/run/US_00000000_000.sh
	cp $GATK_DIR/usage_gatk.sh $script_path
	local usage_file="$RESULTS_DIR_MSVC/usage.$TODAY.txt"

	local summary_script_path=$ANALYSIS_DIR_MSVC/run/summary_mutect.${PROJECT}.pl

	sed -i -e "s/setupLog/${SETUP_LOG//\//\\/}/" $script_path
	sed -i -e "s/usageFile/${usage_file//\//\\/}/" $script_path
	sed -i -e "s/summaryScriptPath/${summary_script_path//\//\\/}/" $script_path

	local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
	local dependency_collect_summary_metrics_all=`cut -f1 $ALL_JOBS_DEPENDENCY`

	local job_id=`qsub -q $QUEUE -o $log_output_path -W depend=$dependency_collect_summary_metrics_all $script_path` 
	echo "`$NOW`$script_path"
	echo "`$NOW`job ID: $job_id"

	script_path=$ANALYSIS_DIR_MSVC/run/usage.php
	cp $GATK_DIR/../../helper/tsvToHtmlTable.php $script_path
 	sed -i -e "s/#tsvFile/usage.txt/" $script_path	
 	sed -i -e "s/#header/Usage Stats/" $script_path

}

####################################################
####################################################

ANALYSIS_DIR_PROJECT=$GROUP_VOL_CGI/analysis/$PROJECT/mutect
RESULTS_DIR_PROJECT=$GROUP_VOL_CGI/results/$PROJECT/mutect

#create and set permissions for analysis project parent directory    
mkdir -p $ANALYSIS_DIR_PROJECT
chmod 770 $ANALYSIS_DIR_PROJECT
    
#create and set permissions for results project parent directory
mkdir -p $RESULTS_DIR_PROJECT
chmod 770 $RESULTS_DIR_PROJECT

#set up directory structure for multi-sample variant calling
mkdir -p $ANALYSIS_DIR_PROJECT/$TODAY
chmod 770 $ANALYSIS_DIR_PROJECT/$TODAY
    
mkdir -p $RESULTS_DIR_PROJECT/$TODAY
chmod 770 $RESULTS_DIR_PROJECT/$TODAY
	
ANALYSIS_DIR_MSVC=$ANALYSIS_DIR_PROJECT/$TODAY/multisample
RESULTS_DIR_MSVC=$RESULTS_DIR_PROJECT/$TODAY/multisample

#create and set permissions for multi-sample variant calling analysis directory
mkdir -p $ANALYSIS_DIR_MSVC
chmod 770 $ANALYSIS_DIR_MSVC
    
#create and set permissions for multi-sample variant calling results directory
mkdir -p $RESULTS_DIR_MSVC
chmod 770 $RESULTS_DIR_MSVC

#create and set permissions for multi-sample metrics results directory
mkdir -p $RESULTS_DIR_MSVC/metrics
chmod 770 $RESULTS_DIR_MSVC/metrics

#intialise log files
RUN_LOG=$ANALYSIS_DIR_MSVC/run.log
echo -n "" > $RUN_LOG
echo -e "DATE\tTIME\tSCRIPT\tSAMPLE\tCHUNK\tSTEP\tSTATUS" >> $RUN_LOG

SETUP_LOG=$ANALYSIS_DIR_MSVC/setup.log
echo -n "" > $SETUP_LOG

BAM_SIZE_FILE=$ANALYSIS_DIR_MSVC/bam_size.txt
echo -n "" > $BAM_SIZE_FILE

#redirect stdout and stderr to terminal and log file
exec > >(tee $SETUP_LOG)
exec 2>&1

echo "`$NOW`setting up GATK3 run..."
echo "`$NOW`GATK version: $GATK_VERSION"
echo "`$NOW`samtools version: $SAMTOOLS_VERSION"
echo "`$NOW`Picard version: $PICARD_VERSION"
echo "`$NOW`R version: $R_VERSION"
echo "`$NOW`NxtGenUtils version: $NXTGENUTILS_VERSION"
echo "`$NOW`Java for running GATK version: $JAVA_VERSION"
echo "`$NOW`Java for running Mutect version: $JAVA_VERSION_MUTECT"
echo "`$NOW`Mutect version: $MUTECT_VERSION"
echo "`$NOW`input directory   : $GROUP_VOL_CGI/results/$PROJECT/mergetag"
echo "`$NOW`sequencing type   : $TYPE"
echo "`$NOW`reference sequence: $REFERENCE_FASTA"
echo "`$NOW`chunk coordinates : $REFERENCE_CHUNKS"

#setup realignment and recalibration jobs
echo "`$NOW`analysis directory: $ANALYSIS_DIR_PROJECT"
echo "`$NOW`results directory: $RESULTS_DIR_PROJECT"

DEPENDENCY_MERGE_MUTECT=afterok
DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL=afterok
    
#initialise file to store PrintReads dependencies for UnifiedGenotyper jobs
PRINT_READS_DEPENDENCY=$ANALYSIS_DIR_MSVC/print_reads_dependencies.tsv
echo -n "" > $PRINT_READS_DEPENDENCY

#initialise file to store Mutect dependencies for post-processing jobs
MUTECT_DEPENDENCY=$ANALYSIS_DIR_MSVC/mutect_dependencies.tsv
echo -n "" > $MUTECT_DEPENDENCY

#initialise file to store dependencies for usage_gatk script
ALL_JOBS_DEPENDENCY=$ANALYSIS_DIR_MSVC/all_jobs_dependencies.tsv
echo -n "" > $ALL_JOBS_DEPENDENCY
	
#create target interval file
if [[ $TARGET_INTERVALS_BED != ""  ]]; then
    
        echo "`$NOW`exome/amplicon coordinates: $TARGET_INTERVALS_BED"
       
	TARGET_INTERVALS_INT=$ANALYSIS_DIR_MSVC/target_intervals.intervals
	#converting BED to interval list skipping blank lines
	#converting to chr:start-end format instead of tab delimited format 
	#as GATK started to refuse parsing tab delimited format for some reason	
	cat $TARGET_INTERVALS_BED | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $TARGET_INTERVALS_INT
		
	#create chunk target intervals
       	for CHUNK_NAME in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`; do
   
	        if [[ $CHUNK_NAME != ""  ]]; then
				
		        CHUNK_INTERVALS_BED=$ANALYSIS_DIR_MSVC/chunk_${CHUNK_NAME}_intervals.bed
			CHUNK_TARGET_INTERVALS_BED=$ANALYSIS_DIR_MSVC/chunk_${CHUNK_NAME}_target_intervals.bed
			CHUNK_TARGET_INTERVALS_INT=$ANALYSIS_DIR_MSVC/chunk_${CHUNK_NAME}_target_intervals.int
												
		        #create chunk intervals bed
			grep -P "chunk_${CHUNK_NAME}\." $REFERENCE_CHUNKS > $CHUNK_INTERVALS_BED
				
		        #create chunk target intervals bed
			intersectBed -wa -a $TARGET_INTERVALS_BED -b $CHUNK_INTERVALS_BED > $CHUNK_TARGET_INTERVALS_BED
				
		        #create chunk target intervals intervals file
			cat $CHUNK_TARGET_INTERVALS_BED | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $CHUNK_TARGET_INTERVALS_INT
				
	        fi
	done
		
fi

echo "`$NOW`see setup log file for more details: $SETUP_LOG"

#create deployment directory
SUMMARY_DEPLOYMENT=$DEPLOYMENT_BASE_DIR/project/$PROJECT/mutect/$TODAY
ssh $DEPLOYMENT_SERVER "mkdir -p -m 775 $SUMMARY_DEPLOYMENT" > /dev/null 2>&1
scp -r ${IMAGE_DIR}/*png $DEPLOYMENT_SERVER:$SUMMARY_DEPLOYMENT/ > /dev/null 2>&1
ssh $DEPLOYMENT_SERVER "chmod -R 664 $SUMMARY_DEPLOYMENT/*png" > /dev/null 2>&1

#create encrypted directory to save vcf files accessable by user
#INC_DIR=`date | md5sum | head -c 15`
#DATA_DEPLOYMENT=$DEPLOYMENT_BASE_DIR/data
#ssh $DEPLOYMENT_SERVER "mkdir -p -m 775 $DATA_DEPLOYMENT/$INC_DIR" > /dev/null 2>&1

#get sample count from sample list skipping blank lines
TOTAL_SAMPLE_COUNT=`sort $SAMPLE_LIST | uniq | awk '/^\s*$/ {next;} { print; }' | wc -l`
SAMPLE_COUNT=0

#for each sample (make sure that each sample and date is unique)... 
sort $SAMPLE_LIST | uniq | while read SAMPLE_NORMAL DATE_NORMAL SAMPLE_TUMOR DATE_TUMOR; do
       	
        if [[ "$SAMPLE_NORMAL" != "" ]] && [[ "$SAMPLE_TUMOR" != "" ]]; then

	        SAMPLE_COUNT=$(( $SAMPLE_COUNT + 1 ))

		echo "`$NOW`"
		echo "`$NOW`"
		echo "`$NOW`processing sample $SAMPLE_COUNT of $TOTAL_SAMPLE_COUNT: $SAMPLE_NORMAL and $SAMPLE_TUMOR"

               
		IN_BAM_SAMPLE=$GROUP_VOL_CGI/results/$PROJECT/mergetag/$DATE_NORMAL/$SAMPLE_NORMAL/$SAMPLE_NORMAL.bam
		ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE_NORMAL
		RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE_NORMAL

		submitSplitBam                        $IN_BAM_SAMPLE \
		    	                              $ANALYSIS_DIR_SAMPLE \
		    	                              $RESULTS_DIR_SAMPLE


		IN_BAM_SAMPLE=$GROUP_VOL_CGI/results/$PROJECT/mergetag/$DATE_TUMOR/$SAMPLE_TUMOR/$SAMPLE_TUMOR.bam		    
		ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE_TUMOR
	        RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE_TUMOR

	        submitSplitBam                        $IN_BAM_SAMPLE \
		    	                              $ANALYSIS_DIR_SAMPLE \
		    	                              $RESULTS_DIR_SAMPLE


		ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE_NORMAL
		RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE_NORMAL

		submitRealignmentAndRecalibrationJobs $SAMPLE_NORMAL \
						      $SAMPLE_TUMOR \
		    	                              $ANALYSIS_DIR_SAMPLE \
		    	                              $RESULTS_DIR_SAMPLE

				    
		ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE_TUMOR
		RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE_TUMOR

		submitRealignmentAndRecalibrationJobs $SAMPLE_TUMOR \
						      $SAMPLE_NORMAL \
		    	                              $ANALYSIS_DIR_SAMPLE \
		    	                              $RESULTS_DIR_SAMPLE


                SAMPLE_PAIR=$SAMPLE_NORMAL.vs.$SAMPLE_TUMOR
		ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE_PAIR
		RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE_PAIR

		submitMuTect                          $SAMPLE_NORMAL \
		                                      $SAMPLE_TUMOR \
		    	                              $ANALYSIS_DIR_SAMPLE \
		    	                              $RESULTS_DIR_SAMPLE 

		echo -n "$DEPENDENCY_MERGE_MUTECT" > $MUTECT_DEPENDENCY	       

	fi

done

#now that the important stuff is done we can run the post-processing steps
SAMPLE_COUNT=0    
sort $SAMPLE_LIST | uniq | while read SAMPLE_NORMAL DATE_NORMAL SAMPLE_TUMOR DATE_TUMOR; do
	
        if [[ "$SAMPLE_NORMAL" != "" ]] && [[ "$SAMPLE_TUMOR" != "" ]]; then
	    
	        SAMPLE_COUNT=$(( $SAMPLE_COUNT + 1 ))
	    
		echo "`$NOW`"
		echo "`$NOW`"
	        echo "`$NOW`post-processing sample $SAMPLE_COUNT of $TOTAL_SAMPLE_COUNT: $SAMPLE_NORMAL and $SAMPLE_TUMOR"
	
		ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE_NORMAL
		RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE_NORMAL

		submitPostProcessingJobs              $SAMPLE_NORMAL \
		                                      $ANALYSIS_DIR_SAMPLE \
               	                                      $RESULTS_DIR_SAMPLE 


		ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE_TUMOR
		RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE_TUMOR

		submitPostProcessingJobs              $SAMPLE_TUMOR \
					              $ANALYSIS_DIR_SAMPLE \
               		 	     	              $RESULTS_DIR_SAMPLE 
		
		echo -n "$DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL" > $ALL_JOBS_DEPENDENCY   

	  fi	    
  
done
 
#merge and plot summary statistics
echo "`$NOW`"
echo "`$NOW`"
submitMergeAndPlotMetricsJob $RESULTS_DIR_MSVC \
			     $ANALYSIS_DIR_MSVC \
			     $PROJECT

#collect data on using computational resources
submitCompUse

echo "`$NOW`"
echo "`$NOW`"
echo "`$NOW`Jobs status can be monitored at $DEPLOYMENT_SERVER/report/project/$PROJECT/mutect/$TODAY"
		                          



