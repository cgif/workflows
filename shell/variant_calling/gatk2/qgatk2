#!/bin/bash

# sets up directory structure and scripts to run GATK
# variant analysis and submits jobs to queue

BASEDIR="$( cd "$( dirname "$0" )" && pwd )"

#GATK_VERSION=2.5-2
GATK_VERSION=2.6-5
SAMTOOLS_VERSION=0.1.18
#!!!Picard Version needs to be > 1.85 for ClipPrimerSequences 
#in gatk2_realign_recalibrate_genome.sh to work properly!!! 
PICARD_VERSION=1.91
R_VERSION=2.15
BEDTOOLS_VERSION=2.13.3
TABIX_VERSION=0.2.6
NXTGENUTILS_VERSION=0.13.0
JAVA_VERSION=jdk-7u25
PATH_STRIP_INDEL_QUALS_SCRIPT=$BASEDIR/stripIndelQuals.sh

module load samtools/$SAMTOOLS_VERSION
module load bedtools/$BEDTOOLS_VERSION

#now
NOW="date +%Y-%m-%d%t%T%t"

#today
TODAY=`date +%Y-%m-%d`
#TODAY="2013-07-03"

#get the directory this script resides in
GROUP_VOL_CGI=/groupvol/cgi
DEPLOYMENT_SERVER=eliot.med.ic.ac.uk
DEPLOYMENT_BASE_DIR=/www/html/report
QUEUE=pqcgi


#GATK configuration

#resources
BUNDLE=/groupvol/cgi/resources/GATK_resource_bundle/2.3/b37

INDELS_1000G=$BUNDLE/1000G_phase1.indels.b37.vcf
INDELS_GOLDSTD=$BUNDLE/Mills_and_1000G_gold_standard.indels.b37.vcf
HIGH_CONF_SNP_1000G=$BUNDLE/1000G_phase1.snps.high_confidence.b37.vcf
DBSNP=$BUNDLE/dbsnp_137.b37.vcf
HAPMAP_SITES=$BUNDLE/hapmap_3.3.b37.sites.vcf
OMNI_1000G=$BUNDLE/1000G_omni2.5.b37.sites.vcf
DBSNP_EX_POST_129=$BUNDLE/dbsnp_137.b37.excluding_sites_after_129.vcf

#downsampling
WG_EXOME_SEQ_DOWNSAMPLING=250
TARGET_SEQ_DOWNSAMPLING=2000

DOWNSAMPLING=$WG_EXOME_SEQ_DOWNSAMPLING

#BAM splitting
BAM_SPLIT_MAX_THREADS=16

#RealignerTargetCreator data threads
RTC_DATATHREADS=2

#RealignRecalibrate reserved CPUs
#should be one more then RTC threads
#as sometimes jobs are killed because
#RealignTargetCreator uses more than
#the specified data threads
RR_DATATHREADS=$(( $RTC_DATATHREADS + 1 ))

#UnifiedGenotyper data threads
UG_DATATHREADS=2

#PrintReads CPU threads
PR_CPUTHREADS=8

#path to text file containing usage information
USAGE="$BASEDIR/gatk2.usage"

# default values for input arguments
REFERENCE_DIR=$GROUP_VOL_CGI/resources/reference/eukaryote/human/hs37d5
REFERENCE_FASTA=$REFERENCE_DIR/hs37d5.fa
REFERENCE_DICT=$REFERENCE_DIR/hs37d5.dict
REFERENCE_CHUNKS_GENOME=$REFERENCE_DIR/hs37d5.chunks.genome.bed
REFERENCE_CHUNKS_EXOME=$REFERENCE_DIR/hs37d5.chunks.exome.bed
REFERENCE_CHUNKS_TARGETED=$REFERENCE_DIR/hs37d5.chunks.targeted.bed
IS_PROJECT_DIR=F
TARGET_INTERVALS_BED=""
REFERENCE_CHUNKS_USER=""
TYPE="WGS"
VARIANT_CALLER=U
PRIMER_COORD_OFFSET=10
PED_FILE="none"
SUBMIT="T"

#parse command line args
while getopts "i:r:s:d:ct:a:v:u:x:p:o:q:g" OPTION;
do

    case "$OPTION" in
	i) INPUT_PATH="$OPTARG";;
	s) SAMPLE_LIST="$OPTARG";;
	c) IS_PROJECT_DIR=T;;
	t) TYPE="$OPTARG";;
	a) TARGET_INTERVALS_BED="$OPTARG";;
	r) REFERENCE_FASTA="$OPTARG";;
	d) REFERENCE_DICT="$OPTARG";;
	u) REFERENCE_CHUNKS_USER="$OPTARG";;
	v) VARIANT_CALLER="$OPTARG";;
	x) AUX_SAMPLE_DIR="$OPTARG";;
	p) PRIMER_COORD_BED="$OPTARG";;
	o) PRIMER_COORD_OFFSET="$OPTARG";;
	q) PED_FILE="$OPTARG";;	
	g) SUBMIT="F";;
	h) cat $USAGE; exit 0;;
	[?]) cat $USAGE; exit 1;;

esac
done


#check if all required arguments are present...
if [[ -z $INPUT_PATH ]] || \
   [[ -z $SAMPLE_LIST ]] || \
   [[ -z $REFERENCE_FASTA ]] || \
   [[ -z $REFERENCE_DICT ]] || \
   [[ -z $TYPE ]]
then

        #...if not print usage and exit
        cat $USAGE
        exit 1
fi

#check if input files and directories exist
#and args a valid

#check if input directory exists
if [[ ! -e $INPUT_PATH ]]
then
        echo "`$NOW`ERROR: input directory does not exist: $INPUT_PATH"
        exit 1
fi

#check if sample list file exists
if [[ ! -e $SAMPLE_LIST ]]
then
        echo "`$NOW`ERROR: sample list file does not exist: $SAMPLE_LIST"
        exit 1
fi

#check if auxiliary sample directory exists
#if auxiliary samples specified in sample list
#file
AUX_SAMPLE_COUNT=`grep 'AUX' $SAMPLE_LIST | wc -l`

if [[ $AUX_SAMPLE_COUNT -ge 1 ]]
then

	#complain if no auxiliary sample directory specified	
	if [[ -z $AUX_SAMPLE_DIR ]]
	then
		echo "`$NOW`ERROR: auxiliary samples in sample list but no auxiliary sample directory specified with -x option."
		exit 1 
	else

		#if specified check if directory exists
		if [[ ! -e $AUX_SAMPLE_DIR ]]
		then
	    	echo "`$NOW`ERROR: auxiliary sample directory does not exist: $AUX_SAMPLE_DIR"
	        exit 1
		fi
	
	fi
fi


#check if reference fasta exists
if [[ ! -e $REFERENCE_FASTA ]]
then
        echo "`$NOW`ERROR: reference sequence file does not exist: $REFERENCE_FASTA"
        exit 1
fi

#check if reference dictionary exists
if [[ ! -e $REFERENCE_DICT ]]
then
        echo "`$NOW`ERROR: reference dictionary file does not exist: $REFERENCE_DICT"
        exit 1
fi

if [[ $TARGET_INTERVALS_BED != ""  ]] && [[ ! -e $TARGET_INTERVALS_BED ]]
then
	echo "`$NOW`ERROR: target interval BED file does not exist: $TARGET_INTERVALS_BED"
        exit 1
fi
    
if [[ $PRIMER_COORD_BED != ""  ]] && [[ ! -e $PRIMER_COORD_BED ]]
then
	echo "`$NOW`ERROR: primer/probe genomic coordinate BED file does not exist: $PRIMER_COORD_BED"
        exit 1
fi

if [[ "$TYPE" == "TARGETED" ]]
then

	#make sure target/amplicon intervals were supplied
	if [[ $TARGET_INTERVALS_BED == ""  ]] 
	then
		echo "`$NOW`ERROR: for targeted sequencing data target- or amplicon-coordinates in BED format have to be supplied via the -a command line argument."
	        exit 1
	fi

	#for high coverage targeted sequencing data
	#HaplotypeCaller will run too long if executed
	#on all targets simultaneously
	REFERENCE_CHUNKS=$REFERENCE_CHUNKS_TARGETED
			
	#set downsampling
	DOWNSAMPLING=$TARGET_SEQ_DOWNSAMPLING

elif [[ "$TYPE" == "EXOME" ]]
then

	#make sure target/amplicon intervals were supplied
#	if [[ $TARGET_INTERVALS_BED == ""  ]] 
#	then
#		echo "`$NOW`ERROR: for exome sequencing data amplicon coordinates in BED format have to be supplied via the -a command line argument, e.g. /groupvol/cgi/resources/target/exome/SureSelect_All_Exon_50M_hg19.tab.bed"
#	        exit 1
#	fi

	#use exome chunks for exome sequencing
	REFERENCE_CHUNKS=$REFERENCE_CHUNKS_EXOME

elif [[ "$TYPE" == "WGS" ]]
then

	#use exome chunks for exome sequencing
	REFERENCE_CHUNKS=$REFERENCE_CHUNKS_GENOME

else

	echo "`$NOW`ERROR: invalid value for sequencing type option (-t) option : $TYPE."
	echo "`$NOW`allowed values: WGS, EXOME, TARGETED."
        exit 1

fi


if [[ "$REFERENCE_CHUNKS_USER" != "" ]] && [[ -e $REFERENCE_CHUNKS_USER ]]
then

        REFERENCE_CHUNKS=$REFERENCE_CHUNKS_USER

elif [[ "$REFERENCE_CHUNKS_USER" != "" ]] && [[ ! -e $REFERENCE_CHUNKS_USER ]]
then

	echo "`$NOW`ERROR: user-defined chunk file does not exist: $REFERENCE_CHUNKS_USER"
        exit 1
fi


#get chunk count
TOTAL_CHUNK_COUNT=0

for CHUNK_NAME in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
do
	
	if [[ $CHUNK_NAME != ""  ]]
	then
		TOTAL_CHUNK_COUNT=$(( $TOTAL_CHUNK_COUNT + 1 ))
	fi
	
done;




#FUNCTIONS
####################################################

#creates job scripts
function submitRealignmentAndRecalibrationJobs {

	#get args
	local input_bam=$1
	local analysis_dir=$2
	local results_dir=$3

	local run_dir=$analysis_dir/run    
	local input_bam_name=`basename $input_bam .bam`
	local sample=$input_bam_name
	local rerun_script=$run_dir/rerun.sh


	#create directory structure for samples
	mkdir -p $analysis_dir
	mkdir -p $results_dir
	mkdir -p $run_dir

	mkdir -p $analysis_dir/chunks

	#realignment
	mkdir -p $analysis_dir/realignment

	#recalibration
	mkdir -p $analysis_dir/recalibration/reports/pre
	mkdir -p $analysis_dir/recalibration/reports/post
	mkdir -p $analysis_dir/recalibration/plots/post

	mkdir -p $results_dir/recalibration/reports/pre
	mkdir -p $results_dir/recalibration/reports/post
	mkdir -p $results_dir/recalibration/plots/post

	#initialise rerun script
	echo "#$sample" > $rerun_script
	echo "" >> $rerun_script
	echo 'NOW="date +%Y-%m-%d%t%T%t"' >>  $rerun_script
	echo "" >>  $rerun_script
	echo 'STAGE=$1' >> $rerun_script
	echo 'IS_DEPENDING=$2' >> $rerun_script
	echo -n 'SAMPLE="' >> $rerun_script
	echo -n $sample >> $rerun_script
	echo '"' >> $rerun_script
	

	echo 'if [[ -z $STAGE ]] || [[ $STAGE == "pre" ]]' >> $rerun_script
	echo "then" >> $rerun_script
	echo "" >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`PRE-PROCESSING"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo ""' >> $rerun_script


	######### script 1: indel realignment and base call score recalibration

	local recalibration_reports=""
	local dependency_realign_recal=afterok

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Split BAM, realign & recalibrate"
	echo "`$NOW`====================================================================================="
 
 	
	echo "`$NOW`splitting BAM files..."
	local chunk_bed_name=`basename $REFERENCE_CHUNKS .bed`

	#get chunk count
	local chunk_ids=(`cut -f5 $REFERENCE_CHUNKS | uniq | awk '/^\s*$/ {next;} {print}'`)
	local chunk_count=`cut -f5 $REFERENCE_CHUNKS | uniq | awk '/^\s*$/ {next;} {print}' | wc -l`
	
	#calculate number of jobs required
	local job_count=`perl -e "use POSIX qw(ceil); print ceil($chunk_count/$BAM_SPLIT_MAX_THREADS);"`

	echo "`$NOW`splitting input BAM $input_bam_name into $chunk_count chunks" 
	echo "`$NOW`max. $BAM_SPLIT_MAX_THREADS chunks per job" 
	echo "`$NOW`$job_count jobs required"

	#initialise file to store job ids for
	#realignment and recalibration job dependencies
	echo -n "" > $run_dir/realign_recalibrate_dependencies.tsv

	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`Split BAM, realign & recalibrate"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo "#split" >> $rerun_script

	echo 'SB_DEPENDENCY=afterok' >> $rerun_script

	#for each subset of chunks...
	local subset_count=0
	for (( c=0; c<$chunk_count; c=c+$BAM_SPLIT_MAX_THREADS ))
	do
            
		local from=$c
		local to=$(($c+$BAM_SPLIT_MAX_THREADS-1))

		if [ $to -ge $chunk_count ]
		then 
			to=$(($chunk_count-1)) 
		fi

		subset_count=$(($subset_count+1))
		local subset_bed=$run_dir/$chunk_bed_name.subset_${subset_count}.bed

		echo "`$NOW`processing chunk subset $subset_count of $job_count..."

		#initialise subset BAM
		echo -n "" > $subset_bed

		#...create subset BED file
		local subset_threads=0
		for (( i=$from; i<=$to; i=i+1 ))
		do
	
			local chunk_id=${chunk_ids[$i]}
			cat $REFERENCE_CHUNKS | awk "{ if (\$5==$chunk_id) { print; } } " >> $subset_bed
	
			subset_threads=$(($subset_threads+1))
		
		done
	
		#calculate temp space
		local file_size_gb=`du $input_bam | perl -e '$in=<>; $in; @tokens=split(/\t/, $in); $size=$tokens[0]; $size_mb=$size/1024; $size_gb=$size_mb/1024; printf("%.0f",$size_gb);'`
		#echo $file_size_gb
		local tmpspace=$(($file_size_gb*2))
	
		#...create and configuring job script
		script_path=$run_dir/splitBam.$input_bam_name.subset_${subset_count}.sh
		cp $BASEDIR/splitBam.sh $script_path

		local output_dir=$analysis_dir/chunks

		sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
		sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
		sed -i -e "s/#sample/$sample/" $script_path
		sed -i -e "s/#inputBam/${input_bam//\//\\/}/" $script_path
		sed -i -e "s/#runDir/${run_dir//\//\\/}/" $script_path
		sed -i -e "s/#outputDir/${output_dir//\//\\/}/" $script_path
		sed -i -e "s/#chunkBed/${subset_bed//\//\\/}/" $script_path
		sed -i -e "s/#threads/$subset_threads/" $script_path
		sed -i -e "s/#tmpSpaceGb/$tmpspace/g" $script_path
		sed -i -e "s/#subset/subset_${subset_count}/" $script_path
	
		#submit job and save job ID to dependency variable
		echo "`$NOW`submitting job script $script_path..."
		
   		log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
   		
   		if [[ $SUBMIT == "T" ]]
   		then
   			local job_id=`qsub -o $log_output_path $script_path` 
		fi
		
		echo "`$NOW`job ID: $job_id"
    		        
		#write qsub to re-submission script
		echo -n 'echo "`$NOW`submitting job script ' >> $rerun_script
		echo -n $script_path >> $rerun_script
		echo '..."' >> $rerun_script
		echo -n 'JOB_ID=`' >> $rerun_script
		echo -n "qsub -o $log_output_path $script_path" >> $rerun_script
		echo '`' >> $rerun_script
		echo 'SB_DEPENDENCY=$SB_DEPENDENCY:$JOB_ID' >> $rerun_script
		echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
		echo '$JOB_ID"' >> $rerun_script
		echo "" >> $rerun_script
	
		#store job id for realignment and recalibration dependency
		for (( i=$from; i<=$to; i=i+1 ))
		do
	
			local chunk_id=${chunk_ids[$i]}
			echo -e "$chunk_id\t$job_id" >> $run_dir/realign_recalibrate_dependencies.tsv	
		
		done
		
	done;


	
	echo "`$NOW`realigning and recalibrating BAM files..."
	
	echo "#realign_recalibrat" >> $rerun_script

	echo 'RR_DEPENDENCY=afterok' >> $rerun_script
						
	local chunk_count=0
	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
	do

		if [[ $chunk_name != ""  ]]	
		then 
			
			chunk_count=$(( $chunk_count + 1 ))			
			local includes_unmapped=F

			echo "`$NOW`-------------------------------------------------------------------------------------"
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."
				
			local chunk="chunk_$chunk_name"

			local chunk_int=$analysis_dir/chunks/$chunk.intervals
			local chunk_bed=$analysis_dir/chunks/$chunk.bed

			echo "`$NOW`creating chunk interval file..."
			#converting BED to interval list skipping blank lines
			#converting to chr:start-end format instead of tab delimited
			#format as GATK started to refuse parsing tab delimited format for some
			#reason
#			cat $REFERENCE_DICT > $chunk_int
#			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS | awk '/^\s*$/ {next;} { print $1 "\t" $2+1 "\t" $3 "\t+\t" $4 }' > $chunk_int
			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $chunk_int
 		
			echo "`$NOW`creating chunk BED file..."
			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS > $chunk_bed

			if [[ $chunk_count -eq $TOTAL_CHUNK_COUNT ]] 		
			then
				includes_unmapped=T
			fi

			local chunk_bam=$analysis_dir/chunks/$input_bam_name.$chunk.bam

			echo "`$NOW`creating and submitting job script to realign and recalibrate chunk..."
			
			local script_path=$run_dir/gatk_realign_recal.$sample.$chunk.sh
			cp $BASEDIR/gatk2_realign_recalibrate_genome.sh $script_path

			sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
			sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
			sed -i -e "s/#picardVersion/$PICARD_VERSION/" $script_path
			sed -i -e "s/#rVersion/$R_VERSION/" $script_path	
			sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
    	  	sed -i -e "s/#nxtGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path
    	  
			sed -i -e "s/#indels1000G/${INDELS_1000G//\//\\/}/" $script_path	
			sed -i -e "s/#indelsGoldStd/${INDELS_GOLDSTD//\//\\/}/" $script_path
			sed -i -e "s/#dbSnp/${DBSNP//\//\\/}/" $script_path
    		
			sed -i -e "s/#inputBam/${chunk_bam//\//\\/}/" $script_path
			sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
			sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
			sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
			sed -i -e "s/#fragmentName/$chunk/" $script_path
			sed -i -e "s/#dataThreads/$RR_DATATHREADS/" $script_path   
			sed -i -e "s/#rtcDataThreads/$RTC_DATATHREADS/" $script_path
			sed -i -e "s/#sample/$sample/" $script_path
			sed -i -e "s/#includesUnmapped/$includes_unmapped/" $script_path
			sed -i -e "s/#primerCoordBed/${PRIMER_COORD_BED//\//\\/}/" $script_path
			sed -i -e "s/#primerCoordOffset/$PRIMER_COORD_OFFSET/" $script_path
			 
			if [[ $TARGET_INTERVALS_BED != ""  ]]
			then
				#sed -i -e "s/fragmentFile/${TARGET_INTERVALS_INT//\//\\/}/" $script_path
				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
				sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path
			else
				sed -i -e "s/#fragmentFile/${chunk_int//\//\\/}/" $script_path
			fi

			recalibration_reports="$recalibration_reports $analysis_dir/recalibration/reports/pre/$sample.$chunk.realigned.recal_data.grp"

			#submit job and save job ID to dependency variable
			local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    		
			#get BAM split dependency
			local split_dependency=`cat $run_dir/realign_recalibrate_dependencies.tsv | grep -P "^$chunk_name\t" | cut -f2` 
    		
			echo "`$NOW`$script_path"

	   		if [[ $SUBMIT == "T" ]]
	   		then
				local job_id=`qsub -o $log_output_path -W depend=afterok:$split_dependency $script_path`
			fi
			
			dependency_realign_recal="$dependency_realign_recal:$job_id"
			echo "`$NOW`job ID: $job_id"
    		        
			#write qsub to re-submission script
			echo -n 'echo "`$NOW`submitting job script ' >> $rerun_script
			echo -n $script_path >> $rerun_script
			echo '..."' >> $rerun_script
			
			echo -n 'JOB_ID=`' >> $rerun_script
			echo -n "qsub -o $log_output_path -W depend=" >> $rerun_script
			echo -n '$SB_DEPENDENCY ' >> $rerun_script
			echo -n "$script_path" >> $rerun_script
			echo '`' >> $rerun_script
			
			echo 'RR_DEPENDENCY=$RR_DEPENDENCY:$JOB_ID' >> $rerun_script
			
			echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
			echo '$JOB_ID"' >> $rerun_script
			echo "" >> $rerun_script

			echo "`$NOW`-------------------------------------------------------------------------------------"
		
		fi

	done


	########## script 2: merge chunk recalibration reports

	local dependency_merge_recal=afterok
	local merged_recal_report=$results_dir/recalibration/reports/pre/$sample.realigned.recal_data.grp

	#create and configure script to merge chunk recalibration reports

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Merge recalibration reports"
	echo "`$NOW`====================================================================================="
	script_path=$run_dir/gatk_merge_recalibration_reports.${sample}.sh
	cp $BASEDIR/gatk2_merge_recalibration_reports.sh $script_path

	sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
	sed -i -e "s/#recalibrationReports/${recalibration_reports//\//\\/}/" $script_path
	sed -i -e "s/#mergedRecalibrationReport/${merged_recal_report//\//\\/}/" $script_path
	sed -i -e "s/#nxtGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path

	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
	sed -i -e "s/#sample/$sample/" $script_path

	#submit job and save job ID to dependency variable
	log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

	echo "`$NOW`$script_path"

	if [[ $SUBMIT == "T" ]]
   	then
		job_id=`qsub -o $log_output_path -W depend=$dependency_realign_recal $script_path`
	fi
	
	echo "`$NOW`job ID: $job_id"
	dependency_merge_recal=$dependency_merge_recal:$job_id


	#write qsub to re-submission script
	#with new realign recalibration dependency
	echo "#merge_recal_report" >> $rerun_script
	
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`Merge recalibration reports"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script

	
	echo -n 'echo "`$NOW`submitting job script ' >> $rerun_script
	echo -n $script_path >> $rerun_script
	echo '..."' >> $rerun_script

	echo -n 'JOB_ID=`' >> $rerun_script
	echo -n "qsub -o $log_output_path -W depend=" >> $rerun_script
	echo -n '$RR_DEPENDENCY ' >> $rerun_script
	echo -n "$script_path" >> $rerun_script
	echo '`' >> $rerun_script

	echo 'MRR_DEPENDENCY=afterok:$JOB_ID' >> $rerun_script
	
	echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
	echo '$JOB_ID"' >> $rerun_script
	echo "" >> $rerun_script


	#add sample to PrintReads dependency file
	echo -n -e "$sample\t" >> $PRINT_READS_DEPENDENCY

	#reset chunk count
	chunk_count=0

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Print reads"
	echo "`$NOW`====================================================================================="


	echo "#print_reads" >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`Print reads"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script

	
	echo 'PR_DEPENDENCY=afterok' >> $rerun_script


	#configure script to print progress summary for submitted jobs
	#if job is completed and log file is created in /run directory
	#script examines whether the output files are in place and not empty
	echo "`$NOW`creating and configuring summary script..."
	local summary_script_path=$run_dir/summary_gatk.$sample.pl
	cp $BASEDIR/summary_gatk.pl $summary_script_path
	chmod 770 $summary_script_path

	sed -i -e "s/projectDirAnalysis/${ANALYSIS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/projectDirResults/${RESULTS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/#project/$PROJECT/" $summary_script_path
	sed -i -e "s/#today/$TODAY/" $summary_script_path
	sed -i -e "s/deploymentServer/$DEPLOYMENT_SERVER/" $summary_script_path
	sed -i -e "s/summaryDeployment/${SUMMARY_DEPLOYMENT//\//\\/}/" $summary_script_path
	sed -i -e "s/dataDeployment/${DATA_DEPLOYMENT//\//\\/}/" $summary_script_path
	sed -i -e "s/summaryResults/${ANALYSIS_DIR_MSVC//\//\\/}/" $summary_script_path
	sed -i -e "s/sampleList/${SAMPLE_LIST//\//\\/}/" $summary_script_path
	sed -i -e "s/refChunks/${REFERENCE_CHUNKS//\//\\/}/" $summary_script_path
	sed -i -e "s/refIntervals/null/" $summary_script_path
	sed -i -e "s/#type/$TYPE/" $summary_script_path
	sed -i -e "s/variantCaller/$VARIANT_CALLER/" $summary_script_path
	sed -i -e "s/encryptedDir/$INC_DIR/" $summary_script_path


	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
	do


		if [[ $chunk_name != ""  ]]
		then 

			chunk_count=$(( $chunk_count + 1 ))	
			echo "`$NOW`-------------------------------------------------------------------------------------"	 
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."

			chunk="chunk_$chunk_name"
			local chunk_int=$analysis_dir/chunks/$chunk.intervals
		
			########## script 3: print reads with recalibrated quality scores 

			#create and configure script to print reads with recalibrated quality scores 

			local realigned_bam_file=$analysis_dir/realignment/$sample.$chunk.realigned.bam
			local realigned_recalibrated_bam_file=$analysis_dir/recalibration/$sample.$chunk.realigned.recalibrated.bam
			local realigned_recalibrated_reduced_bam_file=$analysis_dir/recalibration/$sample.$chunk.realigned.recalibrated.reduced.bam
			local includes_unmapped=F
			if [[ $chunk_count -eq $TOTAL_CHUNK_COUNT ]] 		
			then
				includes_unmapped=T
			fi
		
			echo "`$NOW`creating and submitting job script to print recalibrated reads..."
			script_path=$run_dir/gatk_print_reads.$sample.$chunk.sh
			cp $BASEDIR/gatk2_print_reads_genome.sh $script_path

			sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
			sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
			sed -i -e "s/#nextGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path
			sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path

			sed -i -e "s/#cpuThreads/$PR_CPUTHREADS/" $script_path
			sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
			sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
			sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
			sed -i -e "s/#sample/$sample/" $script_path
			sed -i -e "s/#fragmentName/$chunk/" $script_path
			sed -i -e "s/#realignedBamFile/${realigned_bam_file//\//\\/}/" $script_path
			sed -i -e "s/#recalibrationReport/${merged_recal_report//\//\\/}/" $script_path
			sed -i -e "s/#recalibratedBamOutput/${realigned_recalibrated_bam_file//\//\\/}/" $script_path
			sed -i -e "s/#reducedBamOutput/${realigned_recalibrated_reduced_bam_file//\//\\/}/" $script_path
			sed -i -e "s/#downsamplingThreshold/$DOWNSAMPLING/" $script_path
			sed -i -e "s/#includesUnmapped/$includes_unmapped/" $script_path

			if [[ $TARGET_INTERVALS_BED != ""  ]]
			then
				#sed -i -e "s/fragmentFile/${TARGET_INTERVALS_INT//\//\\/}/" $script_path
				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
				sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path
			else
				sed -i -e "s/#fragmentFile/${chunk_int//\//\\/}/" $script_path
			fi
		
			sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path
			
			#submit job and save job ID to dependency variable
			log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

			echo "`$NOW`$script_path"
	   		if [[ $SUBMIT == "T" ]]
   			then
				job_id=`qsub -o $log_output_path -W depend=$dependency_merge_recal $script_path`
			fi
			
	        echo "`$NOW`job ID: $job_id"
 
			#write qsub to re-submission script
    		#with new merge recalibration report dependency
    		echo -n 'echo "`$NOW`submitting job script ' >> $rerun_script
			echo -n $script_path >> $rerun_script
			echo '..."' >> $rerun_script
    		
    		
    		echo -n 'JOB_ID=`' >> $rerun_script
			echo -n "qsub -o $log_output_path -W depend=" >> $rerun_script
			echo -n '$MRR_DEPENDENCY ' >> $rerun_script
			echo -n "$script_path" >> $rerun_script
			echo '`' >> $rerun_script

			echo 'PR_DEPENDENCY=$PR_DEPENDENCY:$JOB_ID' >> $rerun_script
			
			echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
			echo '$JOB_ID"' >> $rerun_script
			echo "" >> $rerun_script
			echo -n 'echo -e "$SAMPLE\t$JOB_ID" >> ' >> $rerun_script
			echo "$ANALYSIS_DIR_MSVC/run/pre.$chunk.dependencies.txt" >> $rerun_script

			#store job ID in PrintReads dependencies file
			if [[ $chunk_count -ne $TOTAL_CHUNK_COUNT ]]
			then
				echo -n -e "$job_id\t" >> $PRINT_READS_DEPENDENCY
			else
				echo "$job_id" >> $PRINT_READS_DEPENDENCY
			fi
			
			echo "`$NOW`-------------------------------------------------------------------------------------"
	
		fi

	done

	echo 'echo "`$NOW`-------------------------------------------------------------------------------------"' >> $rerun_script

	echo "fi" >> $rerun_script
	echo "" >> $rerun_script

#       to reduce number of job submissions summary script now
#       invoked from gatk2_print_reads_genome.sh script
#
#	log_output_path=`echo $script_path | perl -pe 's/\.pl/\.log/g'`
#	echo "`$NOW`$script_path"
#	local sum_job_id=`qsub -q $QUEUE -o $log_output_path -j oe -W depend=afterany:$job_id -M cgi@imperial.ac.uk $script_path`
#	echo "`$NOW`job ID: $sum_job_id"


	#change permissions on all directories/files created
	chmod -R 770 $analysis_dir
	chmod -R 770 $results_dir

}


function submitVariantCallerMultiSampleJobs {

	local analysis_dir=$1
	local results_dir=$2
	local variant_caller=$3
	local run_dir=$analysis_dir/run

	local rerun_script=$run_dir/rerun.$variant_caller.sh

	#create output directories
	mkdir -p $analysis_dir/chunks
	mkdir -p $analysis_dir/$variant_caller/metrics
	mkdir -p $analysis_dir/$variant_caller/recalibration

	mkdir -p $results_dir/$variant_caller
	mkdir -p $results_dir/$variant_caller/recalibration
	
	mkdir -p $run_dir

	#intitialise rerun script
	echo -n "" > $rerun_script
	echo 'IS_DEPENDING=$1' >> $rerun_script
	echo 'NOW="date +%Y-%m-%d%t%T%t"' >> $rerun_script
	echo "VARIANT_CALLER=$variant_caller" >> $rerun_script

	echo "`$NOW`"	
	echo "`$NOW`"
	echo "`$NOW`====================================================================================="
	echo "`$NOW`Multi-sample $variant_caller..."
	echo "`$NOW`====================================================================================="

	local chunk_count=0

	local dependency_variant_caller=afterok
	local sample=${PROJECT}_multisample
	local raw_vcf_files=""

	
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`Multi-sample $VARIANT_CALLER..."' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo "#variant_calling" >> $rerun_script
	echo 'VC_DEPENDENCY=afterok' >> $rerun_script

	local hc_intervals="null"

	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
	do	
	
		if [[ $chunk_name != ""  ]]
		then 

			chunk_count=$(( $chunk_count + 1 ))	
			echo "`$NOW`-------------------------------------------------------------------------------------"	 
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."

			chunk="chunk_$chunk_name"

			local chunk_int=$analysis_dir/chunks/$chunk.intervals
			local chunk_bed=$analysis_dir/chunks/$chunk.bed

			echo "`$NOW`creating interval file..."
			#converting BED to interval list skipping blank lines
			#converting to chr:start-end format instead of tab delimited
			#format as GATK started to refuse parsing tab delimited format for some
			#reason
			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $chunk_int

			echo "`$NOW`creating BED file..."
			grep -P "chunk_${chunk_name}\." $REFERENCE_CHUNKS > $chunk_bed

		
			#get sample names for multi-sample calling	
			local realigned_recalibrated_bam_file=""
			for sample_record in `cut -f1 $PRINT_READS_DEPENDENCY` 
			do
			
#				echo "`$NOW`adding sample $sample_record to multi-sample variant calling..."
				realigned_recalibrated_bam_file="$realigned_recalibrated_bam_file $ANALYSIS_DIR_PROJECT/$TODAY/$sample_record/recalibration/$sample_record.$chunk.realigned.recalibrated.reduced.bam"
			
			done;

			#get PrintReads job IDs for multi-sample calling job
			# dependencies
			local dependency_print_reads=afterok
			local job_id_column=$(( $chunk_count + 1 ))
			for job_id_record in `cut -f$job_id_column $PRINT_READS_DEPENDENCY` 
			do

				#check if job is still in the queue (either running or queuing)
				#select jobs that are
				#'Q'ueued
				#'R'unning
				#'H'eld
				#'S'uspended
				#'W'aiting
				local alive=`qselect -s QRHSW | grep $job_id_record`
				if [[ $alive != "" ]]
				then
#					echo "`$NOW`adding job $job_id_record to multi-sample variant calling job dependencies..."
					dependency_print_reads="$dependency_print_reads:$job_id_record"
#				else
#					echo "`$NOW`job $job_id_record has finished. Not added to multi-sample variant calling job dependencies..."
				fi			

			done;

			########## script 4: run Variant Caller on realigned and reclibrated chunks
			#for targeted sequencing submit separate
			#HaplotypeCaller job for each target region
			#for exome sequencing use genome chunks

			if [[ "$TYPE" == "TARGETED" ]] && [[ $variant_caller == "haplotypecaller" ]]
			then

				
				#make chunks from target regions/genome chunks
				local hc_intervals_bed=$TARGET_INTERVALS_BED
				local target_intervals_bed_filename=`basename $hc_intervals_bed`
				hc_intervals=$analysis_dir/haplotypecaller/targets/$target_intervals_bed_filename.hc_intervals
				
				mkdir -p $analysis_dir/haplotypecaller/targets
				
	
				#merge overlapping targets/amplicons
				#bedtools merge requires that data is presorted by chromosome and then by start position
				mergeBed -i $hc_intervals_bed \
					| perl -e 'while(<>){ $i++; chomp; print $_."\ttarget_interval_".$i.".1\t".$i."\n"; }' \
					> $hc_intervals

				
				for interval_name in `cut -f 5 $hc_intervals | sort -n | uniq`
				do
				
					local interval="interval_$interval_name"
					local fragment_name=$chunk.$interval

					local target_int=$analysis_dir/haplotypecaller/targets/$interval.intervals
					local target_bed=$analysis_dir/haplotypecaller/targets/$interval.bed

					echo "`$NOW`creating interval file..."
					#converting BED to interval list skipping blank lines
					#converting to chr:start-end format instead of tab delimited
					#format as GATK started to refuse parsing tab delimited format for some
					#reason
					grep -P "interval_${interval_name}\." $hc_intervals | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $target_int
		
					echo "`$NOW`creating BED file..."
					grep -P "interval_${interval_name}\." $hc_intervals > $target_bed

					echo "`$NOW`creating and submitting job scripts to run $variant_caller on target interval $interval_name..."

					local script_path=$run_dir/gatk_haplotype_caller.$fragment_name.sh
		   	 		cp $BASEDIR/gatk2_haplotype_caller_genome.sh $script_path
							
					sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
					sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
					sed -i -e "s/#picardVersion/$PICARD_VERSION/" $script_path
					sed -i -e "s/#rVersion/$R_VERSION/" $script_path
					sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
					
					sed -i -e "s/#dbSnp/${DBSNP//\//\\/}/" $script_path	
					sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
					sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
					sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
					sed -i -e "s/#sampleName/$sample/" $script_path
					sed -i -e "s/#fragmentName/$fragment_name/" $script_path
					sed -i -e "s/#pedFile/${PED_FILE//\//\\/}/" $script_path
					sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path
					sed -i -e "s/#downsamplingThreshold/$DOWNSAMPLING/" $script_path
					sed -i -e "s/#seqType/$TYPE/" $script_path
					
					#submit job and save job ID to dependency variable
		   			local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    		
					#submit job and save job ID to dependency variable
					echo "`$NOW`$script_path"
					
					if [[ $SUBMIT == "T" ]]
   					then
						local job_id=`qsub -o $log_output_path -W depend=$dependency_print_reads $script_path`
					fi
					
					echo "`$NOW`job ID: $job_id"

					#write qsub to re-submission script
					echo "CHUNK=$chunk" >> $rerun_script
					
					echo 'if [[ "$IS_DEPENDING" == "TRUE" ]]' >> $rerun_script
					echo 'then' >> $rerun_script
					echo '   PR_DEPENDENCY=afterok' >> $rerun_script
					echo -n '    for JOB_ID in `cut -f2 ' >> $rerun_script
					echo -n "$run_dir/pre.$chunk.dependencies.txt" >> $rerun_script
					echo '`' >> $rerun_script
					echo '    do' >> $rerun_script
					echo '        ALIVE=`qselect -s QRHSW | grep $JOB_ID`' >> $rerun_script
					echo '        if [[ $ALIVE != "" ]]' >> $rerun_script
					echo '        then' >> $rerun_script
					echo '            PR_DEPENDENCY=$PR_DEPENDENCY:$JOB_ID' >> $rerun_script
					echo '        fi'  >> $rerun_script
					echo '    done' >> $rerun_script
					echo "" >> $rerun_script	
					echo -n '    JOB_ID=`' >> $rerun_script
					echo -n 'qsub -W depend=$PR_DEPENDENCY ' >> $rerun_script
					echo -n "-o $log_output_path $script_path" >> $rerun_script
					echo '`' >> $rerun_script
					echo 'else' >> $rerun_script
					echo -n '    JOB_ID=`' >> $rerun_script
					echo -n "qsub -o $log_output_path $script_path" >> $rerun_script
					echo '`' >> $rerun_script
					echo 'fi' >> $rerun_script
					echo 'VC_DEPENDENCY=$VC_DEPENDENCY:$JOB_ID' >> $rerun_script
					
					echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
					echo '$JOB_ID"' >> $rerun_script
					echo "" >> $rerun_script

					dependency_variant_caller=$dependency_variant_caller:$job_id

					raw_vcf_files="$raw_vcf_files $analysis_dir/haplotypecaller/$sample.$fragment_name.raw.vcf"
					assembled_haplotype_bam_files="$assembled_haplotype_bam_files $sample.$fragment_name.haplotype.bam"
				
				done	
	
			else


				echo "`$NOW`creating and submitting job script to run $variant_caller..."
				if [ $variant_caller == "unifiedgenotyper" ]
				then

					local script_path=$run_dir/gatk_unified_genotyper.$chunk.sh
					cp $BASEDIR/gatk2_unified_genotyper_genome.sh $script_path

				elif [ $variant_caller == "haplotypecaller" ]
				then
					
					local script_path=$run_dir/gatk_haplotype_caller.$chunk.sh
					cp $BASEDIR/gatk2_haplotype_caller_genome.sh $script_path
				
				fi
		  		
				sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
				sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
				sed -i -e "s/#picardVersion/$PICARD_VERSION/" $script_path
				sed -i -e "s/#rVersion/$R_VERSION/" $script_path
				sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path

				sed -i -e "s/#dbSnp/${DBSNP//\//\\/}/" $script_path	
				sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
				sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
				sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
				sed -i -e "s/#sampleName/$sample/" $script_path
				sed -i -e "s/#fragmentName/$chunk/" $script_path
				sed -i -e "s/#pedFile/${PED_FILE//\//\\/}/" $script_path
				sed -i -e "s/#downsamplingThreshold/$DOWNSAMPLING/" $script_path
				sed -i -e "s/#seqType/$TYPE/" $script_path

				if [ $variant_caller == "unifiedgenotyper" ]
				then
					sed -i -e "s/#dataThreads/$UG_DATATHREADS/" $script_path
				fi

				if [[ $TARGET_INTERVALS_BED != "" ]]
				then
				
					target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
					sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path
			        
				else
				
					sed -i -e "s/#fragmentFile/${chunk_int//\//\\/}/" $script_path
			        
				fi

				#submit job and save job ID to dependency variable
				local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    		
				#submit job and save job ID to dependency variable
				echo "`$NOW`$script_path"
				
				if [[ $SUBMIT == "T" ]]
   				then
					local job_id=`qsub -o $log_output_path -W depend=$dependency_print_reads $script_path`
				fi
				
				echo "`$NOW`job ID: $job_id"


				#write qsub to re-submission script
				echo "CHUNK=$chunk" >> $rerun_script
					
				echo 'if [[ "$IS_DEPENDING" == "TRUE" ]]' >> $rerun_script
				echo 'then' >> $rerun_script
				echo '   PR_DEPENDENCY=afterok' >> $rerun_script 
				echo -n '    for JOB_ID in `cut -f2 ' >> $rerun_script
				echo -n "$run_dir/pre.$chunk.dependencies.txt" >> $rerun_script
				echo '`' >> $rerun_script
				echo '    do' >> $rerun_script
				echo '        ALIVE=`qselect -s QRHSW | grep $JOB_ID`' >> $rerun_script
				echo '        if [[ $ALIVE != "" ]]' >> $rerun_script
				echo '        then' >> $rerun_script
				echo '            PR_DEPENDENCY=$PR_DEPENDENCY:$JOB_ID' >> $rerun_script
				echo '        fi'  >> $rerun_script
				echo '    done' >> $rerun_script
				echo "" >> $rerun_script	
				echo -n '    JOB_ID=`' >> $rerun_script
				echo -n 'qsub -W depend=$PR_DEPENDENCY ' >> $rerun_script
				echo -n "-o $log_output_path $script_path" >> $rerun_script
				echo '`' >> $rerun_script
				echo 'else' >> $rerun_script
				echo -n '    JOB_ID=`' >> $rerun_script
				echo -n "qsub -o $log_output_path $script_path" >> $rerun_script
				echo '`' >> $rerun_script
				echo 'fi' >> $rerun_script
				echo 'VC_DEPENDENCY=$VC_DEPENDENCY:$JOB_ID' >> $rerun_script
					
				echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
				echo '$JOB_ID"' >> $rerun_script
				echo "" >> $rerun_script
				dependency_variant_caller=$dependency_variant_caller:$job_id
				assembled_haplotype_bam_files="$assembled_haplotype_bam_files $sample.$chunk.haplotype.bam"

				raw_vcf_files="$raw_vcf_files $analysis_dir/$variant_caller/$sample.$chunk.raw.vcf"

				echo "`$NOW`-------------------------------------------------------------------------------------"

			fi
			# end of if [[ "$TYPE" == "TARGETED" ]] && [[ $variant_caller == "haplotypecaller" ]]

		fi
		# end of if [[ $chunk_name != ""  ]]


	done;


	######### script 5: merge, recalibrating and filtering raw VCF files 

	echo "`$NOW`====================================================================================="
	echo "`$NOW`Merge, recalibrate & filter VCF"
	echo "`$NOW`====================================================================================="

	#configure perl script to print progress summary for submitted jobs
	#if job is completed and log file is created in /run directory
	#script examines whether the output files are in place and not empty
	echo "`$NOW`creating and submitting summary script..."
	local summary_script_path=$run_dir/summary_gatk.$sample.pl
	cp $BASEDIR/summary_gatk.pl $summary_script_path
	chmod 770 $summary_script_path

	sed -i -e "s/projectDirAnalysis/${ANALYSIS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/projectDirResults/${RESULTS_DIR_PROJECT//\//\\/}/" $summary_script_path
	sed -i -e "s/#project/$PROJECT/" $summary_script_path
	sed -i -e "s/#today/$TODAY/" $summary_script_path
	sed -i -e "s/deploymentServer/$DEPLOYMENT_SERVER/" $summary_script_path
	sed -i -e "s/summaryDeployment/${SUMMARY_DEPLOYMENT//\//\\/}/" $summary_script_path
	sed -i -e "s/dataDeployment/${DATA_DEPLOYMENT//\//\\/}/" $summary_script_path
	sed -i -e "s/summaryResults/${ANALYSIS_DIR_MSVC//\//\\/}/" $summary_script_path
	sed -i -e "s/sampleList/${SAMPLE_LIST//\//\\/}/" $summary_script_path
	sed -i -e "s/refChunks/${REFERENCE_CHUNKS//\//\\/}/" $summary_script_path
	sed -i -e "s/refIntervals/${hc_intervals//\//\\/}/" $summary_script_path
	sed -i -e "s/#type/$TYPE/" $summary_script_path
	sed -i -e "s/variantCaller/$VARIANT_CALLER/" $summary_script_path
	sed -i -e "s/encryptedDir/$INC_DIR/" $summary_script_path

	# create a script for merging raw chunk VCF files, recalibrate the merged VCF file and filter
	# calls that don't pass quality filter
	# note: also could do recalibration by suplying all separate VCF files together
	# but we want to keep raw calls file as well, so we merge them first

	if [ $variant_caller == "unifiedgenotyper" ]
	then
		script_path=$run_dir/gatk_recal_ug_vcf.$sample.sh
		cp $BASEDIR/gatk2_recalibrate_vcf_genome.sh $script_path
	elif [ $variant_caller == "haplotypecaller" ]
	then
		script_path=$run_dir/gatk_recal_hc_vcf.$sample.sh
		cp $BASEDIR/gatk2_recalibrate_vcf_genome.sh $script_path
	fi

	local analysis_dir_vc=$analysis_dir/$variant_caller
	local results_dir_vc=$results_dir/$variant_caller

	sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
	sed -i -e "s/#rVersion/$R_VERSION/" $script_path
	sed -i -e "s/#tabixVersion/$TABIX_VERSION/" $script_path	
	sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path

	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
	sed -i -e "s/#indels1000G/${INDELS_1000G//\//\\/}/" $script_path	
	sed -i -e "s/#indelsGoldStd/${INDELS_GOLDSTD//\//\\/}/" $script_path
	sed -i -e "s/#Omni1000G/${OMNI_1000G//\//\\/}/" $script_path
	sed -i -e "s/#highConfSnp1000G/${HIGH_CONF_SNP_1000G//\//\\/}/" $script_path

	#!!!dbSnpExPost129 has to be replaced before dbSnp
	#because otherwise the dbSnp part of the dbSnpExPost129
	#variable would be replaced as well!!!
	sed -i -e "s/#dbSnpExPost129/${DBSNP_EX_POST_129//\//\\/}/" $script_path
	sed -i -e "s/#dbSnp/${DBSNP//\//\\/}/" $script_path

	sed -i -e "s/#hapmapSites/${HAPMAP_SITES//\//\\/}/" $script_path	

	sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
	sed -i -e "s/#analysisDir/${analysis_dir_vc//\//\\/}/" $script_path
	sed -i -e "s/#resultsDir/${results_dir_vc//\//\\/}/" $script_path
	sed -i -e "s/#sampleName/$sample/" $script_path
	sed -i -e "s/#sampleList/${SAMPLE_LIST//\//\\/}/" $script_path

	#we have to use the roundabout Perl way here as there seems to be 
        #a limit to the string length for either sed or the bash substitution 	
	#and the raw VCF string can be very long if the number of amplicons
	#is high!!!
	raw_vcf_files=`echo $raw_vcf_files | perl -pe "s/\//forwardSlash/g"`
	perl -i -pe "s/#rawVcfFiles/$raw_vcf_files/" $script_path
	perl -i -pe "s/forwardSlash/\//g" $script_path

	sed -i -e "s/#sequencingType/$TYPE/" $script_path

	if [ $variant_caller == "unifiedgenotyper" ]
	then
		sed -i -e "s/#variantCaller/UG/" $script_path
	elif [ $variant_caller == "haplotypecaller" ]
    then
		sed -i -e "s/#variantCaller/HC/" $script_path
	fi

 	sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path


	log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
	echo "`$NOW`$script_path"

	if [[ $SUBMIT == "T" ]]
	then
		job_id=`qsub -o $log_output_path -W depend=$dependency_variant_caller $script_path`
	fi
	
	DEPENDENCY_RECALIBRATE_VCF="$DEPENDENCY_RECALIBRATE_VCF:$job_id"

	#commented out as
	#not sure why final summary job should depend on
	#VCF recalibration
    #DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL="$DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL:$job_id"
	echo "`$NOW`job ID: $job_id"

	#write qsub to re-submission script
	#with new Unified Genotyper dependency
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`Merge, recalibrate & filter VCF"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo "" >> $rerun_script
	echo "#vqsr" >> $rerun_script
	echo -n 'JOB_ID=`' >> $rerun_script
	echo -n "qsub -o $log_output_path -W depend=" >> $rerun_script
	echo -n '$VC_DEPENDENCY ' >> $rerun_script
	echo -n "$script_path" >> $rerun_script
	echo '`' >> $rerun_script
	
	echo 'RC_DEPENDENCY=afterok:$JOB_ID' >> $rerun_script

	echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
	echo '$JOB_ID"' >> $rerun_script
	echo "" >> $rerun_script
	echo -n 'echo -e "$VARIANT_CALLER\t$JOB_ID" >> ' >> $rerun_script
	echo "$ANALYSIS_DIR_MSVC/run/variant_calling.dependencies.txt" >> $rerun_script
	echo "" >> $rerun_script


#   to reduce number of job submissions script is now invoked from 
#   gatk2_recalibrate_vcf_genome.sh
#
#	log_output_path=`echo $script_path | perl -pe 's/\.pl/\.log/g'`
#	echo "`$NOW`$script_path"
#	local sum_job_id=`qsub -q $QUEUE -o $log_output_path -j oe -W depend=afterany:$job_id -M cgi@imperial.ac.uk $script_path` 
#	echo "`$NOW`job ID: $sum_job_id"        

	#change permissions on all directories/files created
	chmod -R 770 $analysis_dir
	chmod -R 770 $results_dir
}


function submitPostProcessingJobs {

	#get args
	local sample=$1
	local analysis_dir=$2
	local results_dir=$3

	local run_dir=$analysis_dir/run    

	local rerun_script=$run_dir/rerun.sh

	#recalibration
	mkdir -p $results_dir/recalibration

    #realignment
	mkdir -p $results_dir/realignment
	
	#rerun script
	echo ""
	
	echo 'if [[ -z $STAGE ]] || [[ $STAGE == "post" ]]' >> $rerun_script
	echo "then" >> $rerun_script
	echo "" >> $rerun_script

	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`POST-PROCESSING"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo ""' >> $rerun_script
	echo ""
	########## script 6: merge realigned and recalibrated chunk BAM files
	
	
	echo "`$NOW`====================================================================================="
	echo "`$NOW`Merging realigned, recalibrated and reduced chunk BAM files"
	echo "`$NOW`====================================================================================="
	echo "" >> $rerun_script

	local recalibrated_merged_bam_output_dir=$results_dir/recalibration
	local recalibrated_input_dir=$analysis_dir/recalibration

	local realigned_merged_bam_output_dir=$results_dir/realignment
	local realigned_input_dir=$analysis_dir/realignment

	local dependency_merge_bam="afterok"

	local realigned_bam_files=""
	local realigned_merged_bam_prefix=$sample.realigned
	local realigned_merged_bam=$realigned_merged_bam_output_dir/$realigned_merged_bam_prefix.bam

	local recalibrated_bam_files=""
	local recalibrated_merged_bam_prefix=$sample.realigned.recalibrated
	local recalibrated_merged_bam=$recalibrated_merged_bam_output_dir/$recalibrated_merged_bam_prefix.bam

	local reduced_bam_files=""
	local reduced_merged_bam_prefix=$sample.realigned.recalibrated.reduced
	local reduced_merged_bam=$recalibrated_merged_bam_output_dir/$reduced_merged_bam_prefix.bam
	local dependency_post_recal=afterok

	local chunk_count=0	
	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
	do

		if [[ $chunk_name != ""  ]]
		then 

			chunk_count=$(( $chunk_count + 1 ))	
		
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."
			chunk="chunk_$chunk_name"

			realigned_bam_files="$realigned_bam_files $sample.$chunk.realigned.bam"	   
			recalibrated_bam_files="$recalibrated_bam_files $sample.$chunk.realigned.recalibrated.bam"
			reduced_bam_files="$reduced_bam_files $sample.$chunk.realigned.recalibrated.reduced.bam"
		
		fi

	done;

	echo "`$NOW`creating and submitting job script to merge realigned, recalibrated and reduced chunk BAMs..."
		
	#create and configure job script to merge realigned BAM files		
	script_path=$run_dir/gatk_merge_chunk_bams.$sample.sh
	cp $BASEDIR/gatk2_merge_recalibrated_bams.sh $script_path

 	sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
    sed -i -e "s/#picardVersion/$PICARD_VERSION/" $script_path
	sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
	sed -i -e "s/#pathStripIndelQualsScript/${PATH_STRIP_INDEL_QUALS_SCRIPT//\//\\/}/" $script_path	
	
	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
	sed -i -e "s/#sample/$sample/" $script_path
	sed -i -e "s/#inputDirRealigned/${realigned_input_dir//\//\\/}/" $script_path	
	sed -i -e "s/#inputDirRecalibrated/${recalibrated_input_dir//\//\\/}/" $script_path	
	sed -i -e "s/#realignedBam/$realigned_bam_files/" $script_path
	sed -i -e "s/#recalibratedBam/$recalibrated_bam_files/" $script_path
	sed -i -e "s/#reducedBam/$reduced_bam_files/" $script_path	
	sed -i -e "s/#pathOutputDirRealigned/${realigned_merged_bam_output_dir//\//\\/}/" $script_path
	sed -i -e "s/#pathOutputDirRecalibrated/${recalibrated_merged_bam_output_dir//\//\\/}/" $script_path
	sed -i -e "s/#outputPrefix/$realigned_merged_bam_prefix/" $script_path

	#submit job and save job ID to dependency variable
	log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`

	echo "`$NOW`$script_path"
	
	if [[ $SUBMIT == "T" ]]
   	then
		job_id=`qsub -o $log_output_path -W depend=$DEPENDENCY_RECALIBRATE_VCF $script_path`
	fi
	
	dependency_post_recal="$dependency_post_recal:$job_id"
	
	echo "`$NOW`job ID: $job_id"

	#write qsub to re-submission script
	echo "#merge_bam" >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`Merg realigned, recalibrated and reduced chunk BAM files"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo "" >> $rerun_script
	
	echo -n 'echo "`$NOW`submitting job script ' >> $rerun_script
	echo -n $script_path >> $rerun_script
	echo '..."' >> $rerun_script
			
	echo 'if [[ "$IS_DEPENDING" == "TRUE" ]]' >> $rerun_script
	echo 'then' >> $rerun_script
	echo '   PR_DEPENDENCY=afterok' >> $rerun_script 
	echo -n '    for JOB_ID in `grep $SAMPLE ' >> $rerun_script
	echo -n "$ANALYSIS_DIR_MSVC/run/pre.$chunk.dependencies.txt | cut -f2" >> $rerun_script
	echo '`' >> $rerun_script
	echo '    do' >> $rerun_script
	echo '        ALIVE=`qselect -s QRHSW | grep $JOB_ID`' >> $rerun_script
	echo '        if [[ $ALIVE != "" ]]' >> $rerun_script
	echo '        then' >> $rerun_script
	echo '            PR_DEPENDENCY=$PR_DEPENDENCY:$JOB_ID' >> $rerun_script
	echo '        fi'  >> $rerun_script
	echo '    done' >> $rerun_script
	echo "if [[ -f $ANALYSIS_DIR_MSVC/run/variant_calling.dependencies.txt ]]" >> $rerun_script
	echo "    then" >> $rerun_script
	echo -n '        for JOB_ID in `cut -f2 ' >> $rerun_script
	echo -n "$ANALYSIS_DIR_MSVC/run/variant_calling.dependencies.txt" >> $rerun_script
	echo '`' >> $rerun_script
	echo '        do' >> $rerun_script
	echo '            ALIVE=`qselect -s QRHSW | grep $JOB_ID`' >> $rerun_script
	echo '            if [[ $ALIVE != "" ]]' >> $rerun_script
	echo '            then' >> $rerun_script
	echo '                PR_DEPENDENCY=$PR_DEPENDENCY:$JOB_ID' >> $rerun_script
	echo '            fi'  >> $rerun_script
	echo '         done' >> $rerun_script
	echo "     fi" >> $rerun_script 
	echo "" >> $rerun_script	
	echo 'fi' >> $rerun_script
			
	echo 'if [[ -z $PR_DEPENDENCY ]]' >> $rerun_script
	echo 'then' >> $rerun_script

	echo -n 'JOB_ID=`' >> $rerun_script	
	echo -n "qsub -o $log_output_path $script_path" >> $rerun_script
	echo '`' >> $rerun_script

	echo 'else' >> $rerun_script

	echo -n 'JOB_ID=`' >> $rerun_script	
	echo -n "qsub -o $log_output_path -W depend=" >> $rerun_script
	echo -n '$PR_DEPENDENCY ' >> $rerun_script
	echo -n "$script_path" >> $rerun_script
	echo '`' >> $rerun_script

	echo 'fi' >> $rerun_script

	echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
	echo '$JOB_ID"' >> $rerun_script
	echo "" >> $rerun_script

	echo 'MRB_DEPENDENCY=afterok:$JOB_ID' >> $rerun_script
	echo "" >> $rerun_script
	
	
	echo "`$NOW`done"



	echo "`$NOW`====================================================================================="
	echo "`$NOW`Recalibration and coverage reports"
	echo "`$NOW`====================================================================================="

	#rerun script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	echo 'echo "`$NOW`Recalibration and coverage reports"' >> $rerun_script
	echo 'echo "`$NOW`====================================================================================="' >> $rerun_script
	
	
	#script 7: post-recalibration reports on chunks
	local post_recalibration_reports=""
	
	echo "#post_recal_metrics" >> $rerun_script
	
	chunk_count=0
	for chunk_name in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
	do


		if [[ $chunk_name != ""  ]]	
		then 

			chunk_count=$(( $chunk_count + 1 ))
				

			echo "`$NOW`-------------------------------------------------------------------------------------"
			echo "`$NOW`chunk $chunk_count of $TOTAL_CHUNK_COUNT..."
				
			local chunk="chunk_$chunk_name"

			local chunk_int=$analysis_dir/chunks/$chunk.intervals
			local chunk_bed=$analysis_dir/chunks/$chunk.bed
			local chunk_bam=$analysis_dir/realignment/$sample.$chunk.realigned.bam

			local chunk_pre_recalibration_report=$analysis_dir/recalibration/reports/pre/$sample.$chunk.realigned.recal_data.grp

			echo "`$NOW`creating and submitting job script to get post-recalibration report on chunk..."
			
			local script_path=$run_dir/gatk_postrecal_metrics.$sample.$chunk.sh
			cp $BASEDIR/gatk2_postrecalibration_metrics_genome.sh $script_path

			sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
			sed -i -e "s/#samtoolsVersion/$SAMTOOLS_VERSION/" $script_path
			sed -i -e "s/#picardVersion/$PICARD_VERSION/" $script_path
			sed -i -e "s/#rVersion/$R_VERSION/" $script_path
			sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
    	  
			sed -i -e "s/#indels1000G/${INDELS_1000G//\//\\/}/" $script_path	
			sed -i -e "s/#indelsGoldStd/${INDELS_GOLDSTD//\//\\/}/" $script_path
			sed -i -e "s/#dbSnp/${DBSNP//\//\\/}/" $script_path

			sed -i -e "s/#inputBam/${chunk_bam//\//\\/}/" $script_path
			sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
			sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path
			sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
			sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path	
			sed -i -e "s/#fragmentName/$chunk/" $script_path
			sed -i -e "s/#sample/$sample/" $script_path
			sed -i -e "s/#preRecalibrationReport/${chunk_pre_recalibration_report//\//\\/}/" $script_path

			if [[ $TARGET_INTERVALS_BED != ""  ]]
			then
			
				target_int=$ANALYSIS_DIR_MSVC/chunk_${chunk_name}_target_intervals.int
				sed -i -e "s/#fragmentFile/${target_int//\//\\/}/" $script_path

			else
				sed -i -e "s/#fragmentFile/${chunk_int//\//\\/}/" $script_path
			fi

			post_recalibration_reports="$post_recalibration_reports $analysis_dir/recalibration/reports/post/$sample.$chunk.realigned.recalibrated.recal_data.grp"

			#submit job and save job ID to dependency variable
   			local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    		
			echo "`$NOW`$script_path"
			#local job_id=`qsub -o $log_output_path -W depend=$dependency_merge_bam $script_path`

   			if [[ $SUBMIT == "T" ]]
   			then
				local job_id=`qsub -o $log_output_path -W depend=$DEPENDENCY_RECALIBRATE_VCF $script_path`
			fi
			
			dependency_post_recal="$dependency_post_recal:$job_id"
	
			echo "`$NOW`job ID: $job_id"
	
			#write qsub to re-submission script
			#with new merge recalibrated BAM dependency
			echo -n 'echo "`$NOW`submitting job script ' >> $rerun_script
			echo -n $script_path >> $rerun_script
			echo '..."' >> $rerun_script

			echo 'if [[ -z $PR_DEPENDENCY ]]' >> $rerun_script
			echo 'then' >> $rerun_script

			echo -n 'JOB_ID=`' >> $rerun_script	
			echo -n "qsub -o $log_output_path $script_path" >> $rerun_script
			echo '`' >> $rerun_script

			echo 'else' >> $rerun_script

			echo -n 'JOB_ID=`' >> $rerun_script	
			echo -n "qsub -o $log_output_path -W depend=" >> $rerun_script
			echo -n '$PR_DEPENDENCY ' >> $rerun_script
			echo -n "$script_path" >> $rerun_script
			echo '`' >> $rerun_script

			echo 'fi' >> $rerun_script

			echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
			echo '$JOB_ID"' >> $rerun_script
			echo "" >> $rerun_script
	    		
			echo "`$NOW`-------------------------------------------------------------------------------------"
		
		fi

	done
	
	#script 8: report generation
	local merged_pre_recal_report=$results_dir/recalibration/reports/pre/$sample.realigned.recal_data.grp
	local merged_post_recal_report=$results_dir/recalibration/reports/post/$sample.realigned.recalibrated.recal_data.grp
	local post_recalibration_plots_output_dir=$results_dir/recalibration/plots/post/	
		
	echo "`$NOW`creating and submitting job script to generate summary metrics..."
			
	local script_path=$run_dir/gatk_collect_summary_metrics.$sample.sh
	local summary_script_path=$run_dir/summary_gatk.$sample.pl
	cp $BASEDIR/gatk2_collect_summary_metrics.sh $script_path

	sed -i -e "s/#gatkVersion/$GATK_VERSION/" $script_path
	sed -i -e "s/#rVersion/$R_VERSION/" $script_path
	sed -i -e "s/#javaVersion/$JAVA_VERSION/" $script_path
 	sed -i -e "s/#nxtGenUtilsVersion/$NXTGENUTILS_VERSION/" $script_path
    	  	
   	sed -i -e "s/#analysisDir/${analysis_dir//\//\\/}/" $script_path
	sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path
	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path

 	sed -i -e "s/#reaglignedRecalibratedBam/${recalibrated_merged_bam//\//\\/}/" $script_path
 	sed -i -e "s/#sample/$sample/" $script_path
 	sed -i -e "s/#referenceFasta/${REFERENCE_FASTA//\//\\/}/" $script_path

	sed -i -e "s/#mergedPreRecalibrationReport/${merged_pre_recal_report//\//\\/}/" $script_path
 	sed -i -e "s/#recalibrationReports/${post_recalibration_reports//\//\\/}/" $script_path
 	sed -i -e "s/#mergedPostRecalibrationReport/${merged_post_recal_report//\//\\/}/" $script_path
 	sed -i -e "s/#postRecalibrationPlotsOutputDir/${post_recalibration_plots_output_dir//\//\\/}/" $script_path
 	sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path
	sed -i -e "s/#sequencingType/$TYPE/" $script_path 	
 	
	if [[ $TARGET_INTERVALS_BED != ""  ]]
	then
		sed -i -e "s/#targetIntervals/${TARGET_INTERVALS_INT//\//\\/}/" $script_path
	else
		sed -i -e "s/#targetIntervals/NULL/" $script_path
	fi

 	sed -i -e "s/#summaryScriptPath/${summary_script_path//\//\\/}/" $script_path


 	#submit job and save job ID to dependency variable
   	local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    
	echo "`$NOW`$script_path"
	
	if [[ $SUBMIT == "T" ]]
   	then
		local job_id=`qsub -o $log_output_path -W depend=$dependency_post_recal $script_path`
	fi
	
	echo "`$NOW`job ID: $job_id"

	DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL="$DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL:$job_id"
    
	#write qsub to re-submission script
	#with new post recalibration metrics dependency
	echo "#summary_metrics" >> $rerun_script
	
	echo -n 'echo "`$NOW`submitting job script ' >> $rerun_script
	echo -n $script_path >> $rerun_script
	echo '..."' >> $rerun_script

	echo -n 'JOB_ID=`' >> $rerun_script
 	echo -n "qsub -o $log_output_path -W depend=" >> $rerun_script
	echo -n '$MRB_DEPENDENCY ' >> $rerun_script
	echo -n "$script_path" >> $rerun_script
	echo '`' >> $rerun_script

	echo -n 'echo "`$NOW`job ID: ' >> $rerun_script
	echo '$JOB_ID"' >> $rerun_script
	echo "" >> $rerun_script


	echo 'echo "`$NOW`-------------------------------------------------------------------------------------"' >> $rerun_script

	echo "fi" >> $rerun_script
	echo "" >> $rerun_script


	#print progress summary for submitted jobs
	#if job is completed and log file is created in /run directory
	#script examines whether the output files are in place and not empty

#   to reduce number of job submissions script is now invoked from 
#   gatk2_collect_summary_metrics.sh


#	echo "`$NOW`creating and submitting summary script..."
#	script_path=$run_dir/summary_gatk.$sample.pl
#	log_output_path=`echo $script_path | perl -pe 's/\.pl/\.log/g'`
#	echo "`$NOW`$script_path"
#	local sum_job_id=`qsub -q $QUEUE -o $log_output_path -j oe -W depend=afterany:$job_id -M cgi@imperial.ac.uk $script_path` 
#	echo "`$NOW`job ID: $sum_job_id"


	echo "`$NOW`-------------------------------------------------------------------------------------"
	chmod -R 770 $analysis_dir
	chmod -R 770 $results_dir
	
}

function submitMergeAndPlotMetricsJob {

	#get args
	local results_dir=$1
	local analysis_dir=$2
	local run_dir=$analysis_dir/run
	local project_name=$3
	local sample_summary="$project_name.$TODAY.sample_summary"	
	local sample_interval_summary="$project_name.$TODAY.sample_interval_summary"
	local sample_cumulative_coverage_proportions="$project_name.$TODAY.sample_cumulative_coverage_proportions"
	local dependency_collect_summary_metrics_all=`cat $ALL_JOBS_DEPENDENCY`

	echo "`$NOW`creating and submitting job script to merge and plot metrics..."
		
	#create and configure job script to merge realigned BAM files		
	script_path=$run_dir/plot_summary_metrics.R
	
	cp $BASEDIR/plot_summary_metrics.R $script_path
	
 	sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path	
 	sed -i -e "s/#sampleIntervalSummary/$sample_interval_summary/" $script_path	
 	sed -i -e "s/#sampleCumulativeCoverageProportions/$sample_cumulative_coverage_proportions/" $script_path	

	script_path=$run_dir/gatk_merge_summary_metrics.sh
	cp $BASEDIR/gatk2_merge_summary_metrics.sh $script_path
	transpose_table_script=$BASEDIR/transposeTable.R

	sed -i -e "s/#rVersion/$R_VERSION/" $script_path
 	sed -i -e "s/#resultsDir/${results_dir//\//\\/}/" $script_path	
 	sed -i -e "s/#runDir/${run_dir//\//\\/}/" $script_path
 	sed -i -e "s/#runLog/${RUN_LOG//\//\\/}/" $script_path
 	sed -i -e "s/#type/$TYPE/" $script_path
	sed -i -e "s/#transposeTableScript/${transpose_table_script//\//\\/}/" $script_path
	
	local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
    
	echo "`$NOW`$script_path"
	
	if [[ $SUBMIT == "T" ]]
   	then
		local job_id=`qsub -o $log_output_path -W depend=$dependency_collect_summary_metrics_all $script_path`
	fi

	#configure PHP scripts for coverage summary tables
	
	#sample summary
	script_path=$run_dir/sample_summary.php
	cp $BASEDIR/tsvToHtmlTable.php $script_path

 	sed -i -e "s/#tsvFile/$sample_summary/" $script_path	
 	sed -i -e "s/#header/Sample Coverage Summary/" $script_path

	#sample interval summary
	script_path=$run_dir/sample_interval_summary.php
	cp $BASEDIR/tsvToHtmlTable.php $script_path

 	sed -i -e "s/#tsvFile/$sample_interval_summary/" $script_path	
 	sed -i -e "s/#header/Sample Interval Coverage Summary/" $script_path

	#sample cumulative coverage proportions
	script_path=$run_dir/sample_cumulative_coverage_proportions.php
	cp $BASEDIR/tsvToHtmlTable.php $script_path

 	sed -i -e "s/#tsvFile/$sample_cumulative_coverage_proportions/" $script_path	
 	sed -i -e "s/#header/Sample Cumulative Coverage Proportions/" $script_path

	#copy tsvToXsl.pl script to run folder
	cp $BASEDIR/tsvToXls.pl $run_dir/


	echo "`$NOW`job ID: $job_id"

	echo "`$NOW`-------------------------------------------------------------------------------------"
	
}

function submitCompUse {

	echo "`$NOW`creating and submitting usage script..."
	local script_path=$ANALYSIS_DIR_MSVC/run/usage_gatk.${PROJECT}_multisample.sh
	cp $BASEDIR/usage_gatk.sh $script_path

	local usage_file="$RESULTS_DIR_MSVC/usage.$TODAY.txt"
	local summary_script_path=$ANALYSIS_DIR_MSVC/run/summary_gatk.${PROJECT}_multisample.pl

	sed -i -e "s/setupLog/${SETUP_LOG//\//\\/}/" $script_path
	sed -i -e "s/usageFile/${usage_file//\//\\/}/" $script_path
	sed -i -e "s/summaryScriptPath/${summary_script_path//\//\\/}/" $script_path

	local log_output_path=`echo $script_path | perl -pe 's/\.sh/\.log/g'`
	local dependency_collect_summary_metrics_all=`cut -f1 $ALL_JOBS_DEPENDENCY`
	
	if [[ $SUBMIT == "T" ]]
   	then
		local job_id=`qsub -q $QUEUE -o $log_output_path -W depend=$dependency_collect_summary_metrics_all $script_path` 
	fi
	
	echo "`$NOW`job ID: $job_id"

#	echo "`$NOW`creating and submitting summary script..."
#	script_path=$ANALYSIS_DIR_MSVC/run/summary_gatk.${PROJECT}_multisample.pl
#	log_output_path=`echo $script_path | perl -pe 's/\.pl/\.log/g'`
#	echo "`$NOW`$script_path"
#	local sum_job_id=`qsub -q $QUEUE -o $log_output_path -j oe -W depend=afterany:$job_id -M cgi@imperial.ac.uk $script_path` 
#	echo "`$NOW`job ID: $sum_job_id"

}




####################################################
####################################################

#if the input path is a CGI project directory...
PROJECT=""

DEPENDENCY_RECALIBRATE_VCF=afterok
DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL=afterok

if [[ -d $INPUT_PATH ]] && [[ "$IS_PROJECT_DIR" == "T" ]]
then

    #get project name
    PROJECT=${INPUT_PATH##*/}
    #PROJECT=`basename $INPUT_PATH`

    ANALYSIS_DIR_PROJECT=$GROUP_VOL_CGI/analysis/$PROJECT/gatk2
    RESULTS_DIR_PROJECT=$GROUP_VOL_CGI/results/$PROJECT/gatk2

    #create and set permissions for analysis project parent directory    
    mkdir -p $ANALYSIS_DIR_PROJECT
    chmod 770 $ANALYSIS_DIR_PROJECT
    
    #create and set permissions for results project parent directory
    mkdir -p $RESULTS_DIR_PROJECT
    chmod 770 $RESULTS_DIR_PROJECT

    #set up directory structure for multi-sample variant calling
    mkdir -p $ANALYSIS_DIR_PROJECT/$TODAY
    chmod 770 $ANALYSIS_DIR_PROJECT/$TODAY
    
    mkdir -p $RESULTS_DIR_PROJECT/$TODAY
    chmod 770 $RESULTS_DIR_PROJECT/$TODAY
	
    ANALYSIS_DIR_MSVC=$ANALYSIS_DIR_PROJECT/$TODAY/multisample
    RESULTS_DIR_MSVC=$RESULTS_DIR_PROJECT/$TODAY/multisample

    #create and set permissions for multi-sample variant calling analysis directory
    mkdir -p $ANALYSIS_DIR_MSVC
    chmod 770 $ANALYSIS_DIR_MSVC
    
    #create and set permissions for multi-sample variant calling results directory
    mkdir -p $RESULTS_DIR_MSVC
    chmod 770 $RESULTS_DIR_MSVC

	#intialise log files
	RUN_LOG=$ANALYSIS_DIR_MSVC/run.log
    echo -n "" > $RUN_LOG
	echo -e "DATE\tTIME\tSCRIPT\tSAMPLE\tCHUNK\tSTEP\tSTATUS" >> $RUN_LOG

    SETUP_LOG=$ANALYSIS_DIR_MSVC/setup.log
    echo -n "" > $SETUP_LOG

    #redirect stdout and stderr to terminal and log file
    exec > >(tee $SETUP_LOG)
    exec 2>&1

    #from here redirect stdout and stderr to log file ONLY
#    exec > $SETUP_LOG
#    exec 2>&1

    echo "`$NOW`setting up GATK2 run..."
    echo "`$NOW`GATK version: $GATK_VERSION"
    echo "`$NOW`samtools version: $SAMTOOLS_VERSION"
    echo "`$NOW`Picard version: $PICARD_VERSION"
    echo "`$NOW`R version: $R_VERSION"
    echo "`$NOW`BED tools version: $BEDTOOLS_VERSION"
    echo "`$NOW`TABIX version: $TABIX_VERSION"
    echo "`$NOW`NxtGenUtils version: $NXTGENUTILS_VERSION"
    echo "`$NOW`input directory   : $INPUT_PATH"
    echo "`$NOW`sequencing type   : $TYPE"
    echo "`$NOW`reference sequence: $REFERENCE_FASTA"
    echo "`$NOW`chunk coordinates : $REFERENCE_CHUNKS"
    echo "`$NOW`input path is CGI project directory"


    #setup realignment and recalibration jobs
    echo "`$NOW`analysis directory: $ANALYSIS_DIR_PROJECT"
    echo "`$NOW`results directory: $RESULTS_DIR_PROJECT"
    
    #initialise file to store PrintReads dependencies for UnifiedGenotyper jobs
    PRINT_READS_DEPENDENCY=$ANALYSIS_DIR_MSVC/print_reads_dependencies.tsv
    echo -n "" > $PRINT_READS_DEPENDENCY

    #initialise file to store dependencies for usage_gatk script
    ALL_JOBS_DEPENDENCY=$ANALYSIS_DIR_MSVC/all_jobs_dependencies.tsv
    echo -n "" > $ALL_JOBS_DEPENDENCY
	
    #create target interval file
    
    
    if [[ $TARGET_INTERVALS_BED != ""  ]]
    then
    
    	echo "`$NOW`exome/amplicon coordinates: $TARGET_INTERVALS_BED"

		TARGET_INTERVALS_INT=$ANALYSIS_DIR_MSVC/target_intervals.intervals
		#converting BED to interval list skipping blank lines
		#converting to chr:start-end format instead of tab delimited
		#format as GATK started to refuse parsing tab delimited format for some
		#reason	
		cat $TARGET_INTERVALS_BED | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $TARGET_INTERVALS_INT
		
		#create chunk target intervals
		for CHUNK_NAME in `cut -f 5 $REFERENCE_CHUNKS | sort -n | uniq`
		do
			if [[ $CHUNK_NAME != ""  ]]	
			then
				
				CHUNK_INTERVALS_BED=$ANALYSIS_DIR_MSVC/chunk_${CHUNK_NAME}_intervals.bed
				CHUNK_TARGET_INTERVALS_BED=$ANALYSIS_DIR_MSVC/chunk_${CHUNK_NAME}_target_intervals.bed
				CHUNK_TARGET_INTERVALS_INT=$ANALYSIS_DIR_MSVC/chunk_${CHUNK_NAME}_target_intervals.int
												
				#create chunk intervals bed
				grep -P "chunk_${CHUNK_NAME}\." $REFERENCE_CHUNKS > $CHUNK_INTERVALS_BED
				
				#create chunk target intervals bed
				intersectBed -wa -a $TARGET_INTERVALS_BED -b $CHUNK_INTERVALS_BED > $CHUNK_TARGET_INTERVALS_BED
				
				#create chunk target intervals intervals file
				cat $CHUNK_TARGET_INTERVALS_BED | awk '/^\s*$/ {next;} { print $1 ":" $2+1 "-" $3 }' > $CHUNK_TARGET_INTERVALS_INT
				
			fi
		done
		
    fi

    echo "`$NOW`see setup log file for more details: $SETUP_LOG"



    #create deployment directory
    SUMMARY_DEPLOYMENT=$DEPLOYMENT_BASE_DIR/project/$PROJECT/gatk/$TODAY
    DATA_DEPLOYMENT=$DEPLOYMENT_BASE_DIR/data
    ssh $DEPLOYMENT_SERVER "mkdir -p -m 775 $SUMMARY_DEPLOYMENT" > /dev/null 2>&1
    scp -r ${BASEDIR}/*png $DEPLOYMENT_SERVER:$SUMMARY_DEPLOYMENT/ > /dev/null 2>&1
    ssh $DEPLOYMENT_SERVER "chmod -R 664 $SUMMARY_DEPLOYMENT/*png" > /dev/null 2>&1

    #create encrypted directory to save vcf files accessable by user
    INC_DIR=`date | md5sum | head -c 15`
    ssh $DEPLOYMENT_SERVER "mkdir -p -m 775 $DATA_DEPLOYMENT/$INC_DIR" > /dev/null 2>&1

    #get sample count from sample list skipping blank lines
    TOTAL_SAMPLE_COUNT=`sort $SAMPLE_LIST | uniq | awk '/^\s*$/ {next;} { print; }' | wc -l`
    SAMPLE_COUNT=0

    #for each sample (make sure that each sample and date is unique)... 
    sort $SAMPLE_LIST | uniq | while read SAMPLE DATE SAMPLE_PROJECT
    do
	
	    if [[ "$SAMPLE" != "" ]]
	    then

		    SAMPLE_COUNT=$(( $SAMPLE_COUNT + 1 ))

		    echo "`$NOW`"
		    echo "`$NOW`"
		    echo "`$NOW`processing sample $SAMPLE_COUNT of $TOTAL_SAMPLE_COUNT: $SAMPLE"
	
			if [[ "$DATE" == "AUX" ]]
			then
				IN_BAM_SAMPLE=$AUX_SAMPLE_DIR/$SAMPLE.bam
			else
		    	IN_BAM_SAMPLE=$GROUP_VOL_CGI/results/$SAMPLE_PROJECT/mergetag/$DATE/$SAMPLE/$SAMPLE.bam
		    fi
		    					    
		    ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE
		    RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE

		    submitRealignmentAndRecalibrationJobs $IN_BAM_SAMPLE \
		    	                                  $ANALYSIS_DIR_SAMPLE \
		    	                                  $RESULTS_DIR_SAMPLE 


		
		fi

    done;


    if [[ "$VARIANT_CALLER" == "U" ]] || \
       [[ "$VARIANT_CALLER" == "UH" ]] || \
       [[ "$VARIANT_CALLER" == "HU" ]]
    then
		#submit job for multi-sample variant calling with UnifiedGenotyper...
                VC="unifiedgenotyper"
  		submitVariantCallerMultiSampleJobs $ANALYSIS_DIR_MSVC \
					           $RESULTS_DIR_MSVC \
                                                   $VC
    fi

    if [[ "$VARIANT_CALLER" == "H" ]] || \
       [[ "$VARIANT_CALLER" == "UH" ]] || \
       [[ "$VARIANT_CALLER" == "HU" ]]
    then
               #submit job for multi-sample variant calling with HaplotypeCaller...
               VC="haplotypecaller"
               submitVariantCallerMultiSampleJobs $ANALYSIS_DIR_MSVC \
    				                  $RESULTS_DIR_MSVC \
                                                  $VC
    fi                          	      		
		
		
    #now that the important stuff is done we can run 
    #the post-processing and -analysis steps
    
    SAMPLE_COUNT=0    
    sort $SAMPLE_LIST | uniq | while read SAMPLE DATE
    do
	
	    if [[ "$SAMPLE" != "" ]]
	    then
	    
	    	    SAMPLE_COUNT=$(( $SAMPLE_COUNT + 1 ))
	    
		    echo "`$NOW`"
		    echo "`$NOW`"
		    echo "`$NOW`post-processing sample $SAMPLE_COUNT of $TOTAL_SAMPLE_COUNT: $SAMPLE"
	
			ANALYSIS_DIR_SAMPLE=$ANALYSIS_DIR_PROJECT/$TODAY/$SAMPLE
			RESULTS_DIR_SAMPLE=$RESULTS_DIR_PROJECT/$TODAY/$SAMPLE

		    submitPostProcessingJobs $SAMPLE \
					     $ANALYSIS_DIR_SAMPLE \
               		 	     	     $RESULTS_DIR_SAMPLE 
		
	    fi	    
  
        echo -n "$DEPENDENCY_COLLECT_SUMMARY_METRICS_ALL" > $ALL_JOBS_DEPENDENCY    	   

    done; 

	#merge and plot summary statistics
	submitMergeAndPlotMetricsJob $RESULTS_DIR_MSVC \
								$ANALYSIS_DIR_MSVC \
								$PROJECT

    #collect data on using computational resources
    submitCompUse

    echo "`$NOW`"
    echo "`$NOW`Jobs status can be monitored at $DEPLOYMENT_SERVER/report/project/$PROJECT/gatk/$TODAY"
		                          
else

    #if input is not CGI project directory
    echo "`$NOW`ERROR: qgatk2 currently only supports input in CGI project folders."
    exit 1

fi


